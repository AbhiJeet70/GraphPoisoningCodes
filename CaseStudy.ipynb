{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30775,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CaseStudy",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiJeet70/GraphPoisoningCodes/blob/main/CaseStudy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary library installations (uncomment when needed)\n",
        "!pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.datasets import Planetoid, Amazon, Reddit, Flickr\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.utils import from_networkx\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset function\n",
        "def load_dataset(dataset_name):\n",
        "    if dataset_name in [\"Cora\", \"CiteSeer\", \"PubMed\"]:\n",
        "        dataset = Planetoid(root=f\"./data/{dataset_name}\", name=dataset_name)\n",
        "    elif dataset_name == \"Flickr\":\n",
        "        dataset = Flickr(root=\"./data/Flickr\")\n",
        "    elif dataset_name == \"Reddit\":\n",
        "        dataset = Reddit(root=\"./data/Reddit\")\n",
        "    elif dataset_name == \"AmazonProducts\":\n",
        "        dataset = Amazon(root=\"./data/AmazonProducts\", name='Computers')  # 'Computers' or 'Photo'\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    data = dataset[0]\n",
        "\n",
        "    # Manually check and set num_classes and num_features if not present\n",
        "    if not hasattr(data, 'num_classes'):\n",
        "        data.num_classes = len(data.y.unique())\n",
        "    if not hasattr(data, 'num_features'):\n",
        "        data.num_features = data.x.size(1)\n",
        "\n",
        "    # Convert data to networkx graph (to_undirected)\n",
        "    G = to_networkx(data, to_undirected=True)\n",
        "    return data, G\n",
        "\n",
        "# GCN Model definition\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Evaluation function for GCN\n",
        "def evaluate_gcn(data, epochs=500):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = GCN(input_dim=data.num_features, hidden_dim=64, output_dim=data.num_classes).to(device)\n",
        "    data = data.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(data).argmax(dim=1)\n",
        "        correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "        accuracy = int(correct.sum()) / int(data.test_mask.sum())\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Helper function to get a random non-existent edge\n",
        "def get_random_nonexistent_edge(G):\n",
        "    while True:\n",
        "        u = random.choice(list(G.nodes))\n",
        "        v = random.choice(list(G.nodes))\n",
        "        if not G.has_edge(u, v) and u != v:\n",
        "            return u, v\n",
        "\n",
        "# Poisoning Case 1: Flip percentage of edges from important nodes\n",
        "def case1_poisoning(G, sorted_node_list, flip_percentage):\n",
        "    G_poisoned = G.copy()\n",
        "    num_edges_to_flip = int(flip_percentage * G.number_of_edges())\n",
        "    flipped_edges = 0\n",
        "\n",
        "    for node in sorted_node_list:\n",
        "        if flipped_edges >= num_edges_to_flip:\n",
        "            break\n",
        "        node_edges = list(G_poisoned.edges(node))\n",
        "        num_edges_for_node = int(flip_percentage * len(node_edges))\n",
        "\n",
        "        for edge in random.sample(node_edges, min(num_edges_for_node, num_edges_to_flip - flipped_edges)):\n",
        "            G_poisoned.remove_edge(*edge)\n",
        "            new_edge = get_random_nonexistent_edge(G_poisoned)\n",
        "            G_poisoned.add_edge(*new_edge)\n",
        "            flipped_edges += 1\n",
        "\n",
        "    return G_poisoned\n",
        "\n",
        "# Poisoning Case 2: Calculate equal number of edges to flip\n",
        "def case2_poisoning(G, sorted_node_list, flip_percentage):\n",
        "    G_poisoned = G.copy()\n",
        "    num_edges_to_flip = int(flip_percentage * G.number_of_edges())\n",
        "    flipped_edges = 0\n",
        "\n",
        "    for node in sorted_node_list:\n",
        "        node_edges = list(G_poisoned.edges(node))\n",
        "        for edge in node_edges:\n",
        "            if flipped_edges >= num_edges_to_flip:\n",
        "                return G_poisoned\n",
        "            G_poisoned.remove_edge(*edge)\n",
        "            new_edge = get_random_nonexistent_edge(G_poisoned)\n",
        "            G_poisoned.add_edge(*new_edge)\n",
        "            flipped_edges += 1\n",
        "\n",
        "    return G_poisoned\n",
        "\n",
        "# Meta poisoning technique\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=32, output_dim=1):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Case 3: Meta-poisoning\n",
        "def case3_meta_poisoning(G, sorted_node_list, flip_percentage, mlp):\n",
        "    G_poisoned = G.copy()\n",
        "    num_edges_to_flip = int(flip_percentage * G.number_of_edges())\n",
        "    flipped_edges = 0\n",
        "    for node in sorted_node_list:\n",
        "        if flipped_edges >= num_edges_to_flip:\n",
        "            break\n",
        "        node_edges = list(G_poisoned.edges(node))\n",
        "        for edge in random.sample(node_edges, min(len(node_edges), num_edges_to_flip - flipped_edges)):\n",
        "            edge_tensor = torch.tensor([G.degree(edge[0]), G.degree(edge[1])], dtype=torch.float32).unsqueeze(0)\n",
        "            score = mlp(edge_tensor).item()\n",
        "            if score > 0.5:\n",
        "                if G_poisoned.has_edge(*edge):\n",
        "                    G_poisoned.remove_edge(*edge)\n",
        "                    new_edge = get_random_nonexistent_edge(G_poisoned)\n",
        "                    G_poisoned.add_edge(*new_edge)\n",
        "                    flipped_edges += 1\n",
        "\n",
        "    return G_poisoned\n",
        "\n",
        "# Case 4: Surrogate GCN + Poisoning\n",
        "def case4_ugba_with_surrogate(G, sorted_node_list, data):\n",
        "    G_poisoned = G.copy()\n",
        "\n",
        "    # Train the surrogate GCN within Case 4\n",
        "    class SurrogateGCN(torch.nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "            super(SurrogateGCN, self).__init__()\n",
        "            self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "            self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "            self.embeddings = None  # Store embeddings after the first layer\n",
        "\n",
        "        def forward(self, data):\n",
        "            x, edge_index = data.x, data.edge_index\n",
        "            x = F.relu(self.conv1(x, edge_index))\n",
        "            self.embeddings = x  # Store embeddings from the first layer\n",
        "            x = F.dropout(x, p=0.5, training=self.training)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    surrogate_gcn = SurrogateGCN(input_dim=data.num_features, hidden_dim=64, output_dim=data.num_classes).to(device)\n",
        "    data = data.to(device)\n",
        "    optimizer = torch.optim.Adam(surrogate_gcn.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    surrogate_gcn.train()\n",
        "    for epoch in range(200):  # Train the surrogate GCN\n",
        "        optimizer.zero_grad()\n",
        "        out = surrogate_gcn(data)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    surrogate_gcn.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = surrogate_gcn.embeddings.cpu()\n",
        "\n",
        "    trigger_subgraph = nx.Graph()\n",
        "\n",
        "    # Create a small homophilic subgraph (trigger) using similar embeddings\n",
        "    for i in range(len(sorted_node_list)):\n",
        "        for j in range(i + 1, len(sorted_node_list)):\n",
        "            if torch.norm(embeddings[sorted_node_list[i]] - embeddings[sorted_node_list[j]]) < 1e-3:\n",
        "                trigger_subgraph.add_edge(sorted_node_list[i], sorted_node_list[j])\n",
        "\n",
        "    # Inject the trigger into the poisoned graph\n",
        "    G_poisoned.add_edges_from(trigger_subgraph.edges())\n",
        "\n",
        "    return G_poisoned\n",
        "\n",
        "# Get important nodes based on a given metric\n",
        "def get_important_nodes(G, metric, order=\"descending\"):\n",
        "    if metric == \"degree\":\n",
        "        node_importance = dict(G.degree())\n",
        "    elif metric == \"eigenvector\":\n",
        "        node_importance = nx.eigenvector_centrality(G)\n",
        "    elif metric == \"closeness\":\n",
        "        node_importance = nx.closeness_centrality(G)\n",
        "    elif metric == \"betweenness\":\n",
        "        node_importance = nx.betweenness_centrality(G)\n",
        "    elif metric == \"katz\":\n",
        "        node_importance = nx.katz_centrality(G)\n",
        "    elif metric == \"pagerank\":\n",
        "        node_importance = nx.pagerank(G)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown metric: {metric}\")\n",
        "\n",
        "    return sorted(node_importance, key=node_importance.get, reverse=(order == \"descending\"))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize a results dictionary to store accuracies\n",
        "results = {\n",
        "    'dataset': [],\n",
        "    'case_name': [],  # Ensure this key is initialized\n",
        "    'flip_percentage': [],\n",
        "    'node_selection_method': [],\n",
        "    'clean_accuracy': [],\n",
        "    'poisoned_accuracy': []\n",
        "}\n",
        "\n",
        "# Define the datasets, cases, flip percentages, and node selection methods\n",
        "datasets = [\"Cora\", \"CiteSeer\", \"PubMed\", \"Flickr\", \"Reddit\", \"AmazonProducts\"]\n",
        "case_names = ['percentile', 'absolute', 'meta', 'ugba']  # Updated to string names\n",
        "flip_percentages = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
        "node_selection_methods = [\"degree\", \"eigenvector\", \"closeness\", \"betweenness\", \"katz\", \"pagerank\"]\n",
        "\n",
        "# Poisoning experiment runner function with node selection by metric\n",
        "def _experiment(dataset_name, case_name, flip_percentage, node_selection_method, centrality_metric=\"degree\"):\n",
        "    data, G = load_dataset(dataset_name)\n",
        "\n",
        "    # Select nodes based on centrality metric\n",
        "    sorted_node_list = get_important_nodes(G, centrality_metric)\n",
        "\n",
        "    if case_name == 'percentile':\n",
        "        G_poisoned = case1_poisoning(G, sorted_node_list, flip_percentage)\n",
        "    elif case_name == 'absolute':\n",
        "        G_poisoned = case2_poisoning(G, sorted_node_list, flip_percentage)\n",
        "    elif case_name == 'meta':\n",
        "        mlp = MLP()\n",
        "        G_poisoned = case3_meta_poisoning(G, sorted_node_list, flip_percentage, mlp)\n",
        "    elif case_name == 'ugba':\n",
        "        G_poisoned = case4_ugba_with_surrogate(G, sorted_node_list, data)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported case name: {case_name}\")\n",
        "\n",
        "    # Convert the poisoned graph back to PyG format\n",
        "    data_poisoned = from_networkx(G_poisoned)\n",
        "\n",
        "    # Copy node features, labels, and masks\n",
        "    data_poisoned.x = data.x\n",
        "    data_poisoned.y = data.y\n",
        "    data_poisoned.train_mask = data.train_mask\n",
        "    data_poisoned.test_mask = data.test_mask\n",
        "\n",
        "    # Manually set the num_classes and num_features for poisoned data\n",
        "    data_poisoned.num_classes = data.num_classes\n",
        "    data_poisoned.num_features = data.num_features\n",
        "\n",
        "    # Evaluate GCN performance after poisoning\n",
        "    clean_accuracy = evaluate_gcn(data, epochs=200)\n",
        "    poisoned_accuracy = evaluate_gcn(data_poisoned, epochs=200)\n",
        "\n",
        "    # Store the results\n",
        "    results['dataset'].append(dataset_name)\n",
        "    results['case_name'].append(case_name)\n",
        "    results['flip_percentage'].append(flip_percentage)\n",
        "    results['node_selection_method'].append(node_selection_method)\n",
        "    results['clean_accuracy'].append(clean_accuracy)\n",
        "    results['poisoned_accuracy'].append(poisoned_accuracy)\n",
        "\n",
        "    print(f\"Dataset: {dataset_name}, Case: {case_name}, Flip Percentage: {flip_percentage * 100}%, Node Selection: {node_selection_method}\")\n",
        "    print(f\"Clean Accuracy: {clean_accuracy:.4f}, Poisoned Accuracy: {poisoned_accuracy:.4f}\")\n",
        "\n",
        "# Run experiments for each combination\n",
        "for dataset_name in datasets:\n",
        "    for case_name in case_names:  # Updated to use case_names list\n",
        "        for flip_percentage in flip_percentages:\n",
        "            for node_selection_method in node_selection_methods:\n",
        "                _experiment(dataset_name=dataset_name, case_name=case_name, flip_percentage=flip_percentage, node_selection_method=node_selection_method)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Clean vs. Poisoned Accuracy\n",
        "for dataset in set(results['dataset']):\n",
        "    idx = [j for j, d in enumerate(results['dataset']) if d == dataset]\n",
        "    plt.plot([results['flip_percentage'][j] for j in idx],\n",
        "             [results['clean_accuracy'][j] for j in idx],\n",
        "             marker='o', label=f'{dataset} Clean')\n",
        "\n",
        "    plt.plot([results['flip_percentage'][j] for j in idx],\n",
        "             [results['poisoned_accuracy'][j] for j in idx],\n",
        "             marker='x', linestyle='--', label=f'{dataset} Poisoned')\n",
        "\n",
        "plt.title('GCN Performance: Clean vs Poisoned Accuracy')\n",
        "plt.xlabel('Flip Percentage (%)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks([0.05, 0.1, 0.15, 0.2, 0.25])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-26T15:35:33.477773Z",
          "iopub.execute_input": "2024-09-26T15:35:33.478265Z"
        },
        "trusted": true,
        "id": "CbCxNPgbAjv_",
        "outputId": "87c1107b-cb96-457c-d860-9d54cfec8cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: torch-geometric in /opt/conda/lib/python3.10/site-packages (2.6.1)\nRequirement already satisfied: torch-scatter in /opt/conda/lib/python3.10/site-packages (2.1.2+pt20cpu)\nRequirement already satisfied: torch-sparse in /opt/conda/lib/python3.10/site-packages (0.6.18+pt20cpu)\nRequirement already satisfied: torch-cluster in /opt/conda/lib/python3.10/site-packages (1.6.3+pt20cpu)\nRequirement already satisfied: torch-spline-conv in /opt/conda/lib/python3.10/site-packages (1.2.2+pt20cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.14.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: degree\nClean Accuracy: 0.8080, Poisoned Accuracy: 0.8060\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: eigenvector\nClean Accuracy: 0.8070, Poisoned Accuracy: 0.8050\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: closeness\nClean Accuracy: 0.8100, Poisoned Accuracy: 0.8080\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: betweenness\nClean Accuracy: 0.8100, Poisoned Accuracy: 0.8000\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: katz\nClean Accuracy: 0.8070, Poisoned Accuracy: 0.8010\nDataset: Cora, Case: percentile, Flip Percentage: 5.0%, Node Selection: pagerank\nClean Accuracy: 0.8110, Poisoned Accuracy: 0.8060\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: degree\nClean Accuracy: 0.8040, Poisoned Accuracy: 0.8020\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: eigenvector\nClean Accuracy: 0.8110, Poisoned Accuracy: 0.8090\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: closeness\nClean Accuracy: 0.8030, Poisoned Accuracy: 0.7860\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: betweenness\nClean Accuracy: 0.7980, Poisoned Accuracy: 0.8000\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: katz\nClean Accuracy: 0.8050, Poisoned Accuracy: 0.7950\nDataset: Cora, Case: percentile, Flip Percentage: 10.0%, Node Selection: pagerank\nClean Accuracy: 0.8020, Poisoned Accuracy: 0.8110\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: degree\nClean Accuracy: 0.8160, Poisoned Accuracy: 0.7940\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: eigenvector\nClean Accuracy: 0.8000, Poisoned Accuracy: 0.7820\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: closeness\nClean Accuracy: 0.8000, Poisoned Accuracy: 0.7830\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: betweenness\nClean Accuracy: 0.8010, Poisoned Accuracy: 0.7770\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: katz\nClean Accuracy: 0.8220, Poisoned Accuracy: 0.7750\nDataset: Cora, Case: percentile, Flip Percentage: 15.0%, Node Selection: pagerank\nClean Accuracy: 0.8070, Poisoned Accuracy: 0.7880\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: degree\nClean Accuracy: 0.8060, Poisoned Accuracy: 0.7520\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: eigenvector\nClean Accuracy: 0.8070, Poisoned Accuracy: 0.7520\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: closeness\nClean Accuracy: 0.8020, Poisoned Accuracy: 0.7460\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: betweenness\nClean Accuracy: 0.8020, Poisoned Accuracy: 0.7620\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: katz\nClean Accuracy: 0.8050, Poisoned Accuracy: 0.7430\nDataset: Cora, Case: percentile, Flip Percentage: 20.0%, Node Selection: pagerank\nClean Accuracy: 0.8030, Poisoned Accuracy: 0.7600\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: degree\nClean Accuracy: 0.8070, Poisoned Accuracy: 0.7140\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: eigenvector\nClean Accuracy: 0.7990, Poisoned Accuracy: 0.7500\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: closeness\nClean Accuracy: 0.8100, Poisoned Accuracy: 0.7140\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: betweenness\nClean Accuracy: 0.8110, Poisoned Accuracy: 0.7260\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: katz\nClean Accuracy: 0.8130, Poisoned Accuracy: 0.7330\nDataset: Cora, Case: percentile, Flip Percentage: 25.0%, Node Selection: pagerank\nClean Accuracy: 0.8050, Poisoned Accuracy: 0.7370\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: degree\nClean Accuracy: 0.8190, Poisoned Accuracy: 0.7930\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: eigenvector\nClean Accuracy: 0.7910, Poisoned Accuracy: 0.7790\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: closeness\nClean Accuracy: 0.8050, Poisoned Accuracy: 0.7840\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: betweenness\nClean Accuracy: 0.8080, Poisoned Accuracy: 0.7930\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: katz\nClean Accuracy: 0.8020, Poisoned Accuracy: 0.7890\nDataset: Cora, Case: absolute, Flip Percentage: 5.0%, Node Selection: pagerank\nClean Accuracy: 0.7990, Poisoned Accuracy: 0.8030\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: degree\nClean Accuracy: 0.8090, Poisoned Accuracy: 0.7750\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: eigenvector\nClean Accuracy: 0.8190, Poisoned Accuracy: 0.7840\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: closeness\nClean Accuracy: 0.8090, Poisoned Accuracy: 0.7540\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: betweenness\nClean Accuracy: 0.8140, Poisoned Accuracy: 0.7860\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: katz\nClean Accuracy: 0.8030, Poisoned Accuracy: 0.7790\nDataset: Cora, Case: absolute, Flip Percentage: 10.0%, Node Selection: pagerank\nClean Accuracy: 0.8090, Poisoned Accuracy: 0.7740\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: degree\nClean Accuracy: 0.8110, Poisoned Accuracy: 0.7680\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: eigenvector\nClean Accuracy: 0.8010, Poisoned Accuracy: 0.7570\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: closeness\nClean Accuracy: 0.8110, Poisoned Accuracy: 0.7640\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: betweenness\nClean Accuracy: 0.8130, Poisoned Accuracy: 0.7650\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: katz\nClean Accuracy: 0.8060, Poisoned Accuracy: 0.7660\nDataset: Cora, Case: absolute, Flip Percentage: 15.0%, Node Selection: pagerank\nClean Accuracy: 0.8140, Poisoned Accuracy: 0.7650\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: degree\nClean Accuracy: 0.8100, Poisoned Accuracy: 0.7550\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: eigenvector\nClean Accuracy: 0.7980, Poisoned Accuracy: 0.7470\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: closeness\nClean Accuracy: 0.8120, Poisoned Accuracy: 0.7360\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: betweenness\nClean Accuracy: 0.7980, Poisoned Accuracy: 0.7430\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: katz\nClean Accuracy: 0.8090, Poisoned Accuracy: 0.7490\nDataset: Cora, Case: absolute, Flip Percentage: 20.0%, Node Selection: pagerank\nClean Accuracy: 0.8140, Poisoned Accuracy: 0.7520\nDataset: Cora, Case: absolute, Flip Percentage: 25.0%, Node Selection: degree\nClean Accuracy: 0.8090, Poisoned Accuracy: 0.7340\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}