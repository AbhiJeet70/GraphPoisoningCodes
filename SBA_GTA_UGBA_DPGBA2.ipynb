{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiJeet70/GraphPoisoningCodes/blob/main/SBA_GTA_UGBA_DPGBA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Network Backdoor Attack and Defense Experiment\n",
        "\n",
        "This experiment explores the vulnerability of Graph Neural Networks (GNNs) to various adversarial attacks and evaluates the effectiveness of an adaptive outlier detection defense. We tested five attack methodologies and applied a clustering-based outlier detection to mitigate the attacks, using key datasets like **Cora & PubMed**. Below is a summary of our methodology, findings, and visual analysis.\n",
        "\n",
        "## Methodology Overview\n",
        "\n",
        "### Attack Models\n",
        "Five attack methods were evaluated:\n",
        "\n",
        "1. **SBA-Samp** and **SBA-Gen**: Subgraph-based Backdoor Attack using sampled or generated patterns.\n",
        "2. **GTA**: Graph Trojaning Attack, targeting central nodes.\n",
        "3. **UGBA**: Unnoticeable Graph Backdoor Attack.\n",
        "4. **DPGBA**: Distribution Preserved Graph Backdoor Attack.\n",
        "\n",
        "The attacks aimed to insert triggers into high-centrality nodes to affect the node classification task.\n",
        "\n",
        "### Defense Mechanism\n",
        "To mitigate these attacks, an **Adaptive Outlier Detection Mechanism (Dominant Set)** was used, using an **Autoencoder** for **Out-of-Distribution (OOD) detection**. The adaptive pruning function filtered nodes based on a cohesiveness score, with a pre-filter using a high reconstruction loss threshold followed by a k-nearest neighbor (KNN) clustering-based approach.\n",
        "\n",
        "### Metrics\n",
        "- **ASR (Attack Success Rate)**: Proportion of attacked nodes misclassified as intended by the adversary.\n",
        "- **Clean Accuracy**: Classification accuracy of non-attacked nodes.\n",
        "\n",
        "| Dataset | Model      | Attack   | Defense            | ASR (%) | Clean Accuracy (%) |\n",
        "|---------|------------|----------|--------------------|---------|--------------------|\n",
        "| Cora    | GCN        | SBA-Samp | None               | 90.00   | 88.54              |\n",
        "| Cora    | GCN        | SBA-Samp | Outlier Detection  | 90.00   | 78.93              |\n",
        "| Cora    | GCN        | SBA-Samp | Prune              | 90.00   | 83.92              |\n",
        "| Cora    | GCN        | SBA-Samp | Prune + LD         | 0.00    | 46.40              |\n",
        "| Cora    | GCN        | SBA-Gen  | None               | 100.00  | 87.43              |\n",
        "| Cora    | GCN        | SBA-Gen  | Outlier Detection  | 100.00  | 77.63              |\n",
        "| Cora    | GCN        | SBA-Gen  | Prune              | 90.00   | 81.70              |\n",
        "| Cora    | GCN        | SBA-Gen  | Prune + LD         | 0.00    | 44.92              |\n",
        "| Cora    | GCN        | GTA      | None               | 90.00   | 87.43              |\n",
        "| Cora    | GCN        | GTA      | Outlier Detection  | 90.00   | 78.00              |\n",
        "| Cora    | GCN        | GTA      | Prune              | 100.00  | 79.30              |\n",
        "| Cora    | GCN        | GTA      | Prune + LD         | 0.00    | 43.99              |\n",
        "| Cora    | GCN        | UGBA     | None               | 100.00  | 86.88              |\n",
        "| Cora    | GCN        | UGBA     | Outlier Detection  | 100.00  | 77.45              |\n",
        "| Cora    | GCN        | UGBA     | Prune              | 80.00   | 77.82              |\n",
        "| Cora    | GCN        | UGBA     | Prune + LD         | 0.00    | 43.81              |\n",
        "| Cora    | GCN        | DPGBA    | None               | 100.00  | 86.69              |\n",
        "| Cora    | GCN        | DPGBA    | Outlier Detection  | 100.00  | 77.63              |\n",
        "| Cora    | GCN        | DPGBA    | Prune              | 70.00   | 76.34              |\n",
        "| Cora    | GCN        | DPGBA    | Prune + LD         | 0.00    | 42.88              |\n",
        "| Cora    | GraphSage  | SBA-Samp | None               | 100.00  | 89.09              |\n",
        "| Cora    | GraphSage  | SBA-Samp | Outlier Detection  | 100.00  | 79.11              |\n",
        "| Cora    | GraphSage  | SBA-Samp | Prune              | 90.00   | 78.00              |\n",
        "| Cora    | GraphSage  | SBA-Samp | Prune + LD         | 0.00    | 43.07              |\n",
        "| PubMed  | GCN        | SBA-Samp | None               | 90.00   | 84.30              |\n",
        "| PubMed  | GCN        | SBA-Samp | Outlier Detection  | 82.50   | 76.69              |\n",
        "| PubMed  | GCN        | SBA-Samp | Prune              | 90.00   | 82.17              |\n",
        "| PubMed  | GCN        | SBA-Samp | Prune + LD         | 0.00    | 40.65              |\n",
        "| PubMed  | GCN        | SBA-Gen  | None               | 92.50   | 86.58              |\n",
        "| PubMed  | GCN        | SBA-Gen  | Outlier Detection  | 72.50   | 78.54              |\n",
        "| PubMed  | GCN        | SBA-Gen  | Prune              | 92.50   | 83.90              |\n",
        "| PubMed  | GCN        | SBA-Gen  | Prune + LD         | 0.00    | 42.23              |\n",
        "| PubMed  | GCN        | GTA      | None               | 95.00   | 87.29              |\n",
        "| PubMed  | GCN        | GTA      | Outlier Detection  | 0.00    | 79.33              |\n",
        "| PubMed  | GCN        | GTA      | Prune              | 60.00   | 84.07              |\n",
        "| PubMed  | GCN        | GTA      | Prune + LD         | 0.00    | 42.73              |\n",
        "| PubMed  | GCN        | UGBA     | None               | 95.00   | 87.45              |\n",
        "| PubMed  | GCN        | UGBA     | Outlier Detection  | 85.00   | 79.63              |\n",
        "| PubMed  | GCN        | UGBA     | Prune              | 92.50   | 83.69              |\n",
        "| PubMed  | GCN        | UGBA     | Prune + LD         | 0.00    | 42.53              |\n",
        "| PubMed  | GCN        | DPGBA    | None               | 95.00   | 87.80              |\n",
        "| PubMed  | GCN        | DPGBA    | Outlier Detection  | 20.00   | 79.91              |\n",
        "| PubMed  | GCN        | DPGBA    | Prune              | 92.50   | 83.92              |\n",
        "| PubMed  | GCN        | DPGBA    | Prune + LD         | 0.00    | 42.73              |\n",
        "| PubMed  | GraphSage  | SBA-Samp | None               | 95.00   | 86.84              |\n",
        "| PubMed  | GraphSage  | SBA-Samp | Outlier Detection  | 87.50   | 78.65              |\n",
        "| PubMed  | GraphSage  | SBA-Samp | Prune              | 92.50   | 82.50              |\n",
        "| PubMed  | GraphSage  | SBA-Samp | Prune + LD         | 0.00    | 41.47              |\n",
        "| PubMed  | GraphSage  | SBA-Gen  | None               | 95.00   | 88.66              |\n",
        "| PubMed  | GraphSage  | SBA-Gen  | Outlier Detection  | 75.00   | 80.65              |\n",
        "| PubMed  | GraphSage  | SBA-Gen  | Prune              | 92.50   | 83.64              |\n",
        "| PubMed  | GraphSage  | SBA-Gen  | Prune + LD         | 0.00    | 42.56              |\n",
        "| PubMed  | GraphSage  | GTA      | None               | 95.00   | 88.79              |\n",
        "| PubMed  | GraphSage  | GTA      | Outlier Detection  | 0.00    | 80.73              |\n",
        "| PubMed  | GraphSage  | GTA      | Prune              | 67.50   | 84.48              |\n",
        "| PubMed  | GraphSage  | GTA      | Prune + LD         | 0.00    | 42.89              |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GwouY9MiQc62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install torch-geometric\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "from torch_geometric.datasets import Planetoid, Flickr\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import networkx as nx\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# Check if GPU is available and set device\n",
        "device = torch.device('cpu')  # Use CPU\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "def load_dataset(dataset_name):\n",
        "    if dataset_name in [\"Cora\", \"PubMed\"]:\n",
        "        dataset = Planetoid(root=f\"./data/{dataset_name}\", name=dataset_name)\n",
        "    elif dataset_name == \"Flickr\":\n",
        "        dataset = Flickr(root=\"./data/Flickr\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "    return dataset\n",
        "\n",
        "# Dataset-specific device check (for large datasets like OGB-arxiv)\n",
        "def set_dataset_device(dataset_name):\n",
        "    return torch.device('cpu') if dataset_name == \"OGB-arxiv\" else device\n",
        "\n",
        "# Split dataset into train/validation/test\n",
        "# Updated to randomly mask out 20% of nodes, use 10% for labeled nodes, and 10% for validation\n",
        "def split_dataset(data, test_size=0.2, val_size=0.1):\n",
        "    num_nodes = data.num_nodes\n",
        "    indices = np.arange(num_nodes)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    num_test = int(test_size * num_nodes)\n",
        "    num_val = int(val_size * num_nodes)\n",
        "    num_train = num_nodes - num_test - num_val\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
        "\n",
        "    train_mask[indices[:num_train]] = True\n",
        "    val_mask[indices[num_train:num_train + num_val]] = True\n",
        "    test_mask[indices[num_train + num_val:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    # Mask out 20% nodes for attack performance evaluation (half target, half clean test)\n",
        "    num_target = int(0.1 * num_nodes)  # Half of 20%\n",
        "    target_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
        "    clean_test_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
        "    target_mask[indices[num_train + num_val:num_train + num_val + num_target]] = True\n",
        "    clean_test_mask[indices[num_train + num_val + num_target:]] = True\n",
        "\n",
        "    data.target_mask = target_mask\n",
        "    data.clean_test_mask = clean_test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "# Define GNN Model with multiple architectures (GCN, GraphSAGE, GAT)\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, model_type='GCN'):\n",
        "        super(GNN, self).__init__()\n",
        "        if model_type == 'GCN':\n",
        "            self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "            self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "        elif model_type == 'GraphSage':\n",
        "            self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "            self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
        "        elif model_type == 'GAT':\n",
        "            self.conv1 = GATConv(input_dim, hidden_dim, heads=8, concat=True)\n",
        "            self.conv2 = GATConv(hidden_dim * 8, output_dim, heads=1, concat=False)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Select nodes to poison based on high-centrality (degree centrality) for a stronger impact\n",
        "def select_high_centrality_nodes(data, num_nodes_to_select):\n",
        "    graph = nx.Graph()\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "    graph.add_edges_from(edge_index.T)\n",
        "    centrality = nx.degree_centrality(graph)\n",
        "    sorted_nodes = sorted(centrality, key=centrality.get, reverse=True)\n",
        "    return torch.tensor(sorted_nodes[:num_nodes_to_select], dtype=torch.long).to(device)\n",
        "\n",
        "\n",
        "class TriggerGenerator(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(TriggerGenerator, self).__init__()\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "# OOD Detector (Autoencoder) for detecting poisoned nodes\n",
        "class OODDetector(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(OODDetector, self).__init__()\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, 16),\n",
        "        )\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(16, hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "    def reconstruction_loss(self, x):\n",
        "        decoded = self.forward(x)\n",
        "        loss = F.mse_loss(decoded, x, reduction='none').mean(dim=1)\n",
        "        return loss\n",
        "\n",
        "# Train the OOD Detector\n",
        "def train_ood_detector(ood_detector, data, optimizer, epochs=50):\n",
        "    ood_detector.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "        reconstructed = ood_detector(data.x)\n",
        "        # Use only the training mask to train the OOD detector\n",
        "        loss = F.mse_loss(reconstructed[data.train_mask], data.x[data.train_mask])\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Reconstruction Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Training Function with Poisoned Data\n",
        "def train_with_poisoned_data(model, data, optimizer, poisoned_nodes, trigger_gen, attack, alpha=0.7, early_stopping=False):\n",
        "    # Apply trigger injection\n",
        "    data_poisoned = inject_trigger(data, poisoned_nodes, attack, trigger_gen, alpha)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(100):\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(data_poisoned.x, data_poisoned.edge_index)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = F.cross_entropy(out[data_poisoned.train_mask], data_poisoned.y[data_poisoned.train_mask])\n",
        "\n",
        "        # Backward pass\n",
        "        # Ensure we only retain the graph if we need to perform multiple backward passes\n",
        "        if epoch < 99:  # In all but the last epoch, retain the graph\n",
        "            loss.backward(retain_graph=True)\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Optional: Print loss during training for insight\n",
        "        if early_stopping and epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model, data_poisoned\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Clustering-based Node Selection for UGBA\n",
        "def select_diverse_nodes(data, num_nodes_to_select, num_clusters=10):\n",
        "    \"\"\"\n",
        "    Select nodes using a clustering-based approach to ensure diversity.\n",
        "\n",
        "    Parameters:\n",
        "    - data: PyG data object representing the graph.\n",
        "    - num_nodes_to_select: Number of nodes to select for poisoning.\n",
        "    - num_clusters: Number of clusters to form for diversity.\n",
        "\n",
        "    Returns:\n",
        "    - Tensor containing indices of selected nodes.\n",
        "    \"\"\"\n",
        "    features = data.x.cpu().numpy()\n",
        "\n",
        "    # Perform K-means clustering to find representative nodes\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(features)\n",
        "    labels = kmeans.labels_\n",
        "    cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "    # Select nodes closest to the cluster centers\n",
        "    selected_nodes = []\n",
        "    for i in range(num_clusters):\n",
        "        cluster_indices = np.where(labels == i)[0]\n",
        "        center = cluster_centers[i]\n",
        "        distances = np.linalg.norm(features[cluster_indices] - center, axis=1)\n",
        "        closest_node = cluster_indices[np.argmin(distances)]\n",
        "        selected_nodes.append(closest_node)\n",
        "\n",
        "    # If we need more nodes than clusters, add random nodes from each cluster\n",
        "    while len(selected_nodes) < num_nodes_to_select:\n",
        "        for i in range(num_clusters):\n",
        "            cluster_indices = np.where(labels == i)[0]\n",
        "            random_node = np.random.choice(cluster_indices)\n",
        "            if random_node not in selected_nodes:\n",
        "                selected_nodes.append(random_node)\n",
        "            if len(selected_nodes) >= num_nodes_to_select:\n",
        "                break\n",
        "\n",
        "    return torch.tensor(selected_nodes[:num_nodes_to_select], dtype=torch.long).to(device)\n",
        "\n",
        "# Inject Trigger Function for Different Attacks\n",
        "def inject_trigger(data, poisoned_nodes, attack_type, trigger_gen=None, alpha=0.7, trigger_size=5, trigger_density=0.5, model_type='SW', input_dim=None):\n",
        "    data_poisoned = data.clone()    # Clone data to avoid overwriting the original graph\n",
        "\n",
        "    if attack_type == 'SBA-Samp':\n",
        "        connected_nodes = [data.edge_index[0][data.edge_index[1] == node] for node in poisoned_nodes[:trigger_size]]\n",
        "        avg_features = torch.stack([data.x[nodes].mean(dim=0) if len(nodes) > 0 else data.x.mean(dim=0) for nodes in connected_nodes])\n",
        "        natural_features = avg_features + torch.randn_like(avg_features) * 0.02  # Smaller randomness\n",
        "\n",
        "        # Generate subgraph with realistic density\n",
        "        G = nx.erdos_renyi_graph(trigger_size, trigger_density)\n",
        "        trigger_edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
        "\n",
        "        poisoned_edges = torch.stack([\n",
        "            poisoned_nodes[:trigger_size],\n",
        "            torch.randint(0, data.num_nodes, (trigger_size,), device=device)\n",
        "        ])\n",
        "\n",
        "        data_poisoned.edge_index = torch.cat([data.edge_index, trigger_edge_index.to(device), poisoned_edges.to(device)], dim=1)\n",
        "        data_poisoned.x[poisoned_nodes[:trigger_size]] = natural_features[:trigger_size]\n",
        "\n",
        "    elif attack_type == 'SBA-Gen':\n",
        "        # Enhanced Subgraph-based Backdoor Attack - Generated (SBA-Gen)\n",
        "        connected_nodes = [data.edge_index[0][data.edge_index[1] == node] for node in poisoned_nodes[:trigger_size]]\n",
        "        avg_features = torch.stack([data.x[nodes].mean(dim=0) if len(nodes) > 0 else data.x.mean(dim=0) for nodes in connected_nodes])\n",
        "        natural_features = avg_features + torch.randn_like(avg_features) * 0.03\n",
        "\n",
        "        # Generate subgraph based on realistic local clustering (e.g., Watts-Strogatz or PA)\n",
        "        if model_type == 'SW':\n",
        "            G = nx.watts_strogatz_graph(trigger_size, k=3, p=0.4)  # Increase k to make more realistic local clusters\n",
        "        elif model_type == 'PA':\n",
        "            G = nx.barabasi_albert_graph(trigger_size, m=3)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
        "\n",
        "        # Add edges from generated subgraph and connect to existing nodes\n",
        "        trigger_edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
        "        poisoned_edges = torch.stack([\n",
        "            poisoned_nodes[:trigger_size],\n",
        "            torch.randint(0, data.num_nodes, (trigger_size,), device=device)\n",
        "        ])\n",
        "        data_poisoned.edge_index = torch.cat([data.edge_index, trigger_edge_index.to(device), poisoned_edges.to(device)], dim=1)\n",
        "        data_poisoned.x[poisoned_nodes[:trigger_size]] = natural_features[:trigger_size]\n",
        "\n",
        "    elif attack_type == 'DPGBA':\n",
        "        # Distribution-Preserving Graph Backdoor Attack (DPGBA) simplified\n",
        "        connected_nodes = [data.edge_index[0][data.edge_index[1] == node] for node in poisoned_nodes]\n",
        "        avg_features = torch.stack([data.x[nodes].mean(dim=0) if len(nodes) > 0 else data.x.mean(dim=0) for nodes in connected_nodes])\n",
        "\n",
        "        # Generate trigger features that preserve the distribution\n",
        "        trigger_features = trigger_gen(avg_features)\n",
        "\n",
        "        # Blend trigger features with original features to keep in-distribution\n",
        "        node_alphas = torch.rand(len(poisoned_nodes)).to(device) * 0.3 + 0.5  # Random alpha between 0.5 and 0.8\n",
        "        distribution_preserved_features = node_alphas.unsqueeze(1) * data.x[poisoned_nodes] + (1 - node_alphas.unsqueeze(1)) * trigger_features\n",
        "\n",
        "        # Update poisoned nodes with blended features\n",
        "        data_poisoned.x[poisoned_nodes] = distribution_preserved_features\n",
        "\n",
        "\n",
        "    elif attack_type == 'GTA':\n",
        "        # Enhanced Graph Trojan Attack (GTA)\n",
        "        connected_nodes = [data.edge_index[0][data.edge_index[1] == node] for node in poisoned_nodes]\n",
        "        avg_features = torch.stack([data.x[nodes].mean(dim=0) if len(nodes) > 0 else data.x.mean(dim=0) for nodes in connected_nodes])\n",
        "\n",
        "        trigger_features = avg_features + torch.randn_like(avg_features) * 0.05\n",
        "        data_poisoned.x[poisoned_nodes] = trigger_features\n",
        "\n",
        "    elif attack_type == 'UGBA':\n",
        "        # Unnoticeable Graph Backdoor Attack (UGBA)\n",
        "        diverse_nodes = select_diverse_nodes(data, len(poisoned_nodes), num_clusters=10)\n",
        "        connected_nodes = [data.edge_index[0][data.edge_index[1] == node] for node in diverse_nodes]\n",
        "        avg_features = torch.stack([data.x[nodes].mean(dim=0) if len(nodes) > 0 else data.x.mean(dim=0) for nodes in connected_nodes])\n",
        "        trigger_features = trigger_gen(avg_features) * 0.6 + avg_features * 0.4\n",
        "        refined_trigger_features = trigger_features + torch.randn_like(avg_features) * 0.02\n",
        "        data_poisoned.x[diverse_nodes] = refined_trigger_features\n",
        "\n",
        "\n",
        "    return data_poisoned\n",
        "\n",
        "# Defense 1: Outlier Detection (OD)\n",
        "def defense_outlier_detection(ood_detector, data, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Identifies outlier nodes using an OOD detector and removes their influence by modifying labels and features.\n",
        "\n",
        "    Parameters:\n",
        "    - ood_detector: Pre-trained OOD detector to identify outliers.\n",
        "    - data: PyG data object representing the graph.\n",
        "    - threshold: Quantile threshold for identifying outliers (e.g., 0.9 means top 10% of loss values are outliers).\n",
        "\n",
        "    Returns:\n",
        "    - pruned_nodes: Set of nodes identified as outliers.\n",
        "    - data: Updated PyG data object with modified features and labels for outliers.\n",
        "    \"\"\"\n",
        "    ood_detector.eval()\n",
        "    with torch.no_grad():\n",
        "        reconstruction_loss = ood_detector.reconstruction_loss(data.x)\n",
        "        threshold_loss = torch.quantile(reconstruction_loss, threshold).item()\n",
        "\n",
        "        # Identify outliers with reconstruction loss higher than the threshold\n",
        "        outliers = torch.where(reconstruction_loss > threshold_loss)[0]\n",
        "        pruned_nodes = set(outliers.cpu().numpy())\n",
        "\n",
        "        # Update data to reflect removal of outlier influence\n",
        "        if len(pruned_nodes) > 0:\n",
        "            data.y[outliers] = -1  # Discard labels for outliers\n",
        "            data.x[outliers] = data.x.mean(dim=0).to(device)  # Replace features with average feature to mitigate impact\n",
        "\n",
        "    return pruned_nodes, data\n",
        "\n",
        "# Defense 2: Adaptive Prune Edges based on Cosine Similarity\n",
        "def defense_prune_edges(data, quantile_threshold=0.9):\n",
        "    \"\"\"\n",
        "    Prunes edges based on adaptive cosine similarity between node features.\n",
        "\n",
        "    Parameters:\n",
        "    - data: PyG data object representing the graph.\n",
        "    - quantile_threshold: Quantile to determine pruning threshold (e.g., 0.9 means pruning edges in the top 10% dissimilar).\n",
        "\n",
        "    Returns:\n",
        "    - data: Updated PyG data object with pruned edges.\n",
        "    \"\"\"\n",
        "    features = data.x\n",
        "    norm_features = F.normalize(features, p=2, dim=1)  # Normalize features\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Calculate cosine similarity for each edge\n",
        "    src, dst = edge_index[0], edge_index[1]\n",
        "    cosine_similarities = torch.sum(norm_features[src] * norm_features[dst], dim=1)\n",
        "\n",
        "    # Adaptive threshold based on quantile of similarity distribution\n",
        "    similarity_threshold = torch.quantile(cosine_similarities, quantile_threshold).item()\n",
        "\n",
        "    # Keep edges with cosine similarity above the threshold\n",
        "    pruned_mask = cosine_similarities >= similarity_threshold\n",
        "    pruned_edges = edge_index[:, pruned_mask]\n",
        "\n",
        "    # Update edge index with pruned edges\n",
        "    data.edge_index = pruned_edges\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Defense 3: Prune + LD (Adaptive Prune and Selective Discard Labels)\n",
        "def defense_prune_and_discard_labels(data, quantile_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Prunes edges based on adaptive cosine similarity and discards labels of nodes connected by pruned edges selectively.\n",
        "\n",
        "    Parameters:\n",
        "    - data: PyG data object representing the graph.\n",
        "    - quantile_threshold: Quantile threshold for cosine similarity pruning (e.g., 0.2 means pruning edges in the bottom 20%).\n",
        "\n",
        "    Returns:\n",
        "    - data: Updated PyG data object with pruned edges and selectively discarded labels.\n",
        "    \"\"\"\n",
        "    features = data.x\n",
        "    norm_features = F.normalize(features, p=2, dim=1)  # Normalize features using PyTorch\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Calculate cosine similarity for each edge\n",
        "    src, dst = edge_index[0], edge_index[1]\n",
        "    cosine_similarities = torch.sum(norm_features[src] * norm_features[dst], dim=1)\n",
        "\n",
        "    # Use quantile to determine adaptive threshold for pruning\n",
        "    adaptive_threshold = torch.quantile(cosine_similarities, quantile_threshold).item()\n",
        "\n",
        "    # Mask edges with similarity below the adaptive threshold\n",
        "    pruned_mask = cosine_similarities < adaptive_threshold\n",
        "    pruned_edges = edge_index[:, ~pruned_mask]  # Retain edges that are above the threshold\n",
        "\n",
        "    # Update edge index with pruned edges\n",
        "    data.edge_index = pruned_edges\n",
        "\n",
        "    # Selectively discard labels of nodes connected by many pruned edges\n",
        "    pruned_src, pruned_dst = edge_index[:, pruned_mask]\n",
        "    pruned_nodes_count = torch.bincount(torch.cat([pruned_src, pruned_dst]), minlength=data.num_nodes)\n",
        "\n",
        "    # Only discard labels if the node has a high count of pruned edges\n",
        "    threshold_count = int(torch.median(pruned_nodes_count).item())  # Use median count as a threshold\n",
        "    nodes_to_discard = torch.where(pruned_nodes_count > threshold_count)[0]\n",
        "\n",
        "    data.y[nodes_to_discard] = -1  # Use -1 to represent discarded labels\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compute ASR and Clean Accuracy (using .detach() to avoid retaining computation graph)\n",
        "def compute_metrics(model, data, poisoned_nodes):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index).detach()\n",
        "        _, pred = out.max(dim=1)\n",
        "        asr = (pred[poisoned_nodes] == data.y[poisoned_nodes]).sum().item() / len(poisoned_nodes) * 100\n",
        "        clean_acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu()) * 100\n",
        "    return asr, clean_acc\n",
        "\n",
        "# Visualize PCA for Attacks\n",
        "# Added function to visualize PCA projections of node embeddings for different attacks\n",
        "def visualize_pca_for_attacks(attack_embeddings_dict):\n",
        "    pca = PCA(n_components=2)\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    for i, (attack, attack_data) in enumerate(attack_embeddings_dict.items(), 1):\n",
        "        # Extract the node embeddings and poisoned nodes indices\n",
        "        embeddings = attack_data['data'].cpu().numpy()\n",
        "        poisoned_nodes = attack_data['poisoned_nodes'].cpu().numpy()\n",
        "\n",
        "        # Apply PCA to the node embeddings\n",
        "        pca_result = pca.fit_transform(embeddings)\n",
        "\n",
        "        # Create masks for clean and poisoned nodes\n",
        "        clean_mask = np.ones(embeddings.shape[0], dtype=bool)\n",
        "        clean_mask[poisoned_nodes] = False\n",
        "\n",
        "        # Extract clean and poisoned node embeddings after PCA\n",
        "        clean_embeddings = pca_result[clean_mask]\n",
        "        poisoned_embeddings = pca_result[~clean_mask]\n",
        "\n",
        "        # Plotting clean and poisoned nodes\n",
        "        plt.subplot(2, 3, i)\n",
        "        plt.scatter(clean_embeddings[:, 0], clean_embeddings[:, 1], s=10, alpha=0.5, label='Clean Nodes', c='b')\n",
        "        plt.scatter(poisoned_embeddings[:, 0], poisoned_embeddings[:, 1], s=10, alpha=0.8, label='Poisoned Nodes', c='r')\n",
        "        plt.title(f'PCA Visualization for {attack}')\n",
        "        plt.xlabel('PCA Component 1')\n",
        "        plt.ylabel('PCA Component 2')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "import gc\n",
        "\n",
        "# Run all attacks and apply defenses\n",
        "def run_all_attacks():\n",
        "    datasets = [\"Cora\", \"PubMed\", \"Flickr\"]\n",
        "    results_summary = []\n",
        "\n",
        "    for dataset_name in datasets:\n",
        "        dataset = load_dataset(dataset_name)\n",
        "        data = dataset[0].to(device)\n",
        "        input_dim = data.num_features\n",
        "        output_dim = dataset.num_classes if isinstance(dataset.num_classes, int) else dataset.num_classes[0]\n",
        "        data = split_dataset(data)\n",
        "\n",
        "        # Dataset-specific poisoning budgets\n",
        "        dataset_budgets = {\n",
        "            'Cora': 10,\n",
        "            'PubMed': 40,\n",
        "            'Flickr': 160\n",
        "        }\n",
        "        poisoned_node_budget = dataset_budgets.get(dataset_name, 10)\n",
        "\n",
        "        # Define GNN models for experiments\n",
        "        model_types = ['GCN', 'GraphSage', 'GAT']\n",
        "\n",
        "        for model_type in model_types:\n",
        "            # Initialize model, optimizer, and Trigger Generator with smaller hidden sizes\n",
        "            model = GNN(input_dim=input_dim, hidden_dim=64, output_dim=output_dim, model_type=model_type).to(device)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "            trigger_gen = TriggerGenerator(input_dim=input_dim, hidden_dim=64).to(device)\n",
        "            ood_detector = OODDetector(input_dim=input_dim, hidden_dim=64).to(device)\n",
        "\n",
        "            # Train OOD detector\n",
        "            ood_optimizer = torch.optim.Adam(ood_detector.parameters(), lr=0.001)\n",
        "            train_ood_detector(ood_detector, data, ood_optimizer)\n",
        "\n",
        "            # Select nodes to poison based on high-centrality (degree centrality) for a stronger impact\n",
        "            poisoned_nodes = select_high_centrality_nodes(data, poisoned_node_budget)\n",
        "\n",
        "            # Define different attacks\n",
        "            attack_methods = ['SBA-Samp', 'SBA-Gen', 'GTA', 'UGBA', 'DPGBA']\n",
        "\n",
        "            for attack in attack_methods:\n",
        "                # Train model with poisoned data\n",
        "                trained_model, data_poisoned = train_with_poisoned_data(\n",
        "                    model, data, optimizer, poisoned_nodes, trigger_gen, attack, alpha=0.7, early_stopping=True\n",
        "                )\n",
        "\n",
        "                # Compute ASR and Clean Accuracy before applying any defense\n",
        "                asr, clean_acc = compute_metrics(trained_model, data_poisoned, poisoned_nodes)\n",
        "                results_summary.append({\n",
        "                    \"Dataset\": dataset_name,\n",
        "                    \"Model\": model_type,\n",
        "                    \"Attack\": attack,\n",
        "                    \"Defense\": \"None\",\n",
        "                    \"ASR\": asr,\n",
        "                    \"Clean Accuracy\": clean_acc\n",
        "                })\n",
        "                print(f\"Dataset: {dataset_name}, Model: {model_type}, Attack: {attack}, Defense: None - ASR: {asr:.2f}%, Clean Accuracy: {clean_acc:.2f}%\")\n",
        "\n",
        "                # Apply defenses\n",
        "                # Defense 1: Outlier Detection (OD)\n",
        "                pruned_nodes, data_poisoned_od = defense_outlier_detection(ood_detector, data_poisoned.clone(), threshold=0.9)\n",
        "                asr_od, clean_acc_od = compute_metrics(trained_model, data_poisoned_od, poisoned_nodes)\n",
        "                results_summary.append({\n",
        "                    \"Dataset\": dataset_name,\n",
        "                    \"Model\": model_type,\n",
        "                    \"Attack\": attack,\n",
        "                    \"Defense\": \"Outlier Detection\",\n",
        "                    \"ASR\": asr_od,\n",
        "                    \"Clean Accuracy\": clean_acc_od\n",
        "                })\n",
        "                print(f\"Dataset: {dataset_name}, Model: {model_type}, Attack: {attack}, Defense: Outlier Detection - ASR: {asr_od:.2f}%, Clean Accuracy: {clean_acc_od:.2f}%\")\n",
        "\n",
        "                # Defense 2: Prune\n",
        "                data_poisoned_prune = defense_prune_edges(data_poisoned.clone(), quantile_threshold=0.8)\n",
        "                asr_prune, clean_acc_prune = compute_metrics(trained_model, data_poisoned_prune, poisoned_nodes)\n",
        "                results_summary.append({\n",
        "                    \"Dataset\": dataset_name,\n",
        "                    \"Model\": model_type,\n",
        "                    \"Attack\": attack,\n",
        "                    \"Defense\": \"Prune\",\n",
        "                    \"ASR\": asr_prune,\n",
        "                    \"Clean Accuracy\": clean_acc_prune\n",
        "                })\n",
        "                print(f\"Dataset: {dataset_name}, Model: {model_type}, Attack: {attack}, Defense: Prune - ASR: {asr_prune:.2f}%, Clean Accuracy: {clean_acc_prune:.2f}%\")\n",
        "\n",
        "                # Defense 3: Prune + LD\n",
        "                data_poisoned_prune_ld = defense_prune_and_discard_labels(data_poisoned.clone(), quantile_threshold=0.8)\n",
        "                asr_prune_ld, clean_acc_prune_ld = compute_metrics(trained_model, data_poisoned_prune_ld, poisoned_nodes)\n",
        "                results_summary.append({\n",
        "                    \"Dataset\": dataset_name,\n",
        "                    \"Model\": model_type,\n",
        "                    \"Attack\": attack,\n",
        "                    \"Defense\": \"Prune + LD\",\n",
        "                    \"ASR\": asr_prune_ld,\n",
        "                    \"Clean Accuracy\": clean_acc_prune_ld\n",
        "                })\n",
        "                print(f\"Dataset: {dataset_name}, Model: {model_type}, Attack: {attack}, Defense: Prune + LD - ASR: {asr_prune_ld:.2f}%, Clean Accuracy: {clean_acc_prune_ld:.2f}%\")\n",
        "\n",
        "                # Clear memory after each attack-defense cycle\n",
        "                variables_to_clear = ['model', 'optimizer', 'trigger_gen', 'ood_detector', 'data_poisoned', 'trained_model']\n",
        "                for var_name in variables_to_clear:\n",
        "                    if var_name in locals():\n",
        "                        del locals()[var_name]\n",
        "\n",
        "                # Release memory\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "    # Summarize Results in a Table\n",
        "    results_df = pd.DataFrame(results_summary)\n",
        "    print(\"\\nSummary of Attack Success Rate and Clean Accuracy Before and After Defenses:\")\n",
        "    print(results_df)\n",
        "\n",
        "    # Optionally, save results to CSV\n",
        "    results_df.to_csv(\"backdoor_attack_results_summary.csv\", index=False)\n",
        "\n",
        "run_all_attacks()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ayB58aQHQc66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d661f8-0d5f-4f52-ad5f-5737577ef252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Reconstruction Loss: 0.0213\n",
            "Epoch 10, Reconstruction Loss: 0.0153\n",
            "Epoch 20, Reconstruction Loss: 0.0132\n",
            "Epoch 30, Reconstruction Loss: 0.0124\n",
            "Epoch 40, Reconstruction Loss: 0.0121\n",
            "Epoch 0, Loss: 1.9662\n",
            "Epoch 10, Loss: 1.4551\n",
            "Epoch 20, Loss: 0.9441\n",
            "Epoch 30, Loss: 0.6230\n",
            "Epoch 40, Loss: 0.4510\n",
            "Epoch 50, Loss: 0.3446\n",
            "Epoch 60, Loss: 0.2920\n",
            "Epoch 70, Loss: 0.2578\n",
            "Epoch 80, Loss: 0.2321\n",
            "Epoch 90, Loss: 0.2144\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Samp, Defense: None - ASR: 90.00%, Clean Accuracy: 88.54%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 90.00%, Clean Accuracy: 78.93%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Samp, Defense: Prune - ASR: 90.00%, Clean Accuracy: 83.92%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 46.40%\n",
            "Epoch 0, Loss: 0.1922\n",
            "Epoch 10, Loss: 0.1802\n",
            "Epoch 20, Loss: 0.1651\n",
            "Epoch 30, Loss: 0.1521\n",
            "Epoch 40, Loss: 0.1414\n",
            "Epoch 50, Loss: 0.1413\n",
            "Epoch 60, Loss: 0.1319\n",
            "Epoch 70, Loss: 0.1298\n",
            "Epoch 80, Loss: 0.1182\n",
            "Epoch 90, Loss: 0.1143\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Gen, Defense: None - ASR: 100.00%, Clean Accuracy: 87.43%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 77.63%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Gen, Defense: Prune - ASR: 90.00%, Clean Accuracy: 81.70%\n",
            "Dataset: Cora, Model: GCN, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 44.92%\n",
            "Epoch 0, Loss: 0.1039\n",
            "Epoch 10, Loss: 0.1000\n",
            "Epoch 20, Loss: 0.0972\n",
            "Epoch 30, Loss: 0.0918\n",
            "Epoch 40, Loss: 0.0898\n",
            "Epoch 50, Loss: 0.0862\n",
            "Epoch 60, Loss: 0.0799\n",
            "Epoch 70, Loss: 0.0817\n",
            "Epoch 80, Loss: 0.0757\n",
            "Epoch 90, Loss: 0.0791\n",
            "Dataset: Cora, Model: GCN, Attack: GTA, Defense: None - ASR: 90.00%, Clean Accuracy: 87.43%\n",
            "Dataset: Cora, Model: GCN, Attack: GTA, Defense: Outlier Detection - ASR: 90.00%, Clean Accuracy: 78.00%\n",
            "Dataset: Cora, Model: GCN, Attack: GTA, Defense: Prune - ASR: 100.00%, Clean Accuracy: 79.30%\n",
            "Dataset: Cora, Model: GCN, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.99%\n",
            "Epoch 0, Loss: 0.0756\n",
            "Epoch 10, Loss: 0.0701\n",
            "Epoch 20, Loss: 0.0666\n",
            "Epoch 30, Loss: 0.0673\n",
            "Epoch 40, Loss: 0.0625\n",
            "Epoch 50, Loss: 0.0601\n",
            "Epoch 60, Loss: 0.0577\n",
            "Epoch 70, Loss: 0.0571\n",
            "Epoch 80, Loss: 0.0539\n",
            "Epoch 90, Loss: 0.0507\n",
            "Dataset: Cora, Model: GCN, Attack: UGBA, Defense: None - ASR: 100.00%, Clean Accuracy: 86.88%\n",
            "Dataset: Cora, Model: GCN, Attack: UGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 77.45%\n",
            "Dataset: Cora, Model: GCN, Attack: UGBA, Defense: Prune - ASR: 80.00%, Clean Accuracy: 77.82%\n",
            "Dataset: Cora, Model: GCN, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.81%\n",
            "Epoch 0, Loss: 0.0520\n",
            "Epoch 10, Loss: 0.0534\n",
            "Epoch 20, Loss: 0.0477\n",
            "Epoch 30, Loss: 0.0515\n",
            "Epoch 40, Loss: 0.0465\n",
            "Epoch 50, Loss: 0.0448\n",
            "Epoch 60, Loss: 0.0442\n",
            "Epoch 70, Loss: 0.0452\n",
            "Epoch 80, Loss: 0.0407\n",
            "Epoch 90, Loss: 0.0436\n",
            "Dataset: Cora, Model: GCN, Attack: DPGBA, Defense: None - ASR: 100.00%, Clean Accuracy: 86.69%\n",
            "Dataset: Cora, Model: GCN, Attack: DPGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 77.63%\n",
            "Dataset: Cora, Model: GCN, Attack: DPGBA, Defense: Prune - ASR: 70.00%, Clean Accuracy: 76.34%\n",
            "Dataset: Cora, Model: GCN, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.88%\n",
            "Epoch 0, Reconstruction Loss: 0.0215\n",
            "Epoch 10, Reconstruction Loss: 0.0153\n",
            "Epoch 20, Reconstruction Loss: 0.0131\n",
            "Epoch 30, Reconstruction Loss: 0.0123\n",
            "Epoch 40, Reconstruction Loss: 0.0121\n",
            "Epoch 0, Loss: 1.9448\n",
            "Epoch 10, Loss: 1.1982\n",
            "Epoch 20, Loss: 0.5776\n",
            "Epoch 30, Loss: 0.3108\n",
            "Epoch 40, Loss: 0.1894\n",
            "Epoch 50, Loss: 0.1390\n",
            "Epoch 60, Loss: 0.0980\n",
            "Epoch 70, Loss: 0.0760\n",
            "Epoch 80, Loss: 0.0580\n",
            "Epoch 90, Loss: 0.0507\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Samp, Defense: None - ASR: 100.00%, Clean Accuracy: 89.09%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 79.11%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Samp, Defense: Prune - ASR: 90.00%, Clean Accuracy: 78.00%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.07%\n",
            "Epoch 0, Loss: 0.0395\n",
            "Epoch 10, Loss: 0.0332\n",
            "Epoch 20, Loss: 0.0276\n",
            "Epoch 30, Loss: 0.0230\n",
            "Epoch 40, Loss: 0.0201\n",
            "Epoch 50, Loss: 0.0170\n",
            "Epoch 60, Loss: 0.0161\n",
            "Epoch 70, Loss: 0.0151\n",
            "Epoch 80, Loss: 0.0137\n",
            "Epoch 90, Loss: 0.0138\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Gen, Defense: None - ASR: 100.00%, Clean Accuracy: 89.46%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.93%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Gen, Defense: Prune - ASR: 100.00%, Clean Accuracy: 76.16%\n",
            "Dataset: Cora, Model: GraphSage, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 41.59%\n",
            "Epoch 0, Loss: 0.0172\n",
            "Epoch 10, Loss: 0.0123\n",
            "Epoch 20, Loss: 0.0124\n",
            "Epoch 30, Loss: 0.0097\n",
            "Epoch 40, Loss: 0.0097\n",
            "Epoch 50, Loss: 0.0075\n",
            "Epoch 60, Loss: 0.0063\n",
            "Epoch 70, Loss: 0.0063\n",
            "Epoch 80, Loss: 0.0068\n",
            "Epoch 90, Loss: 0.0065\n",
            "Dataset: Cora, Model: GraphSage, Attack: GTA, Defense: None - ASR: 100.00%, Clean Accuracy: 88.72%\n",
            "Dataset: Cora, Model: GraphSage, Attack: GTA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.56%\n",
            "Dataset: Cora, Model: GraphSage, Attack: GTA, Defense: Prune - ASR: 100.00%, Clean Accuracy: 75.42%\n",
            "Dataset: Cora, Model: GraphSage, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 40.67%\n",
            "Epoch 0, Loss: 0.0062\n",
            "Epoch 10, Loss: 0.0053\n",
            "Epoch 20, Loss: 0.0055\n",
            "Epoch 30, Loss: 0.0061\n",
            "Epoch 40, Loss: 0.0049\n",
            "Epoch 50, Loss: 0.0045\n",
            "Epoch 60, Loss: 0.0043\n",
            "Epoch 70, Loss: 0.0034\n",
            "Epoch 80, Loss: 0.0036\n",
            "Epoch 90, Loss: 0.0032\n",
            "Dataset: Cora, Model: GraphSage, Attack: UGBA, Defense: None - ASR: 100.00%, Clean Accuracy: 88.35%\n",
            "Dataset: Cora, Model: GraphSage, Attack: UGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.00%\n",
            "Dataset: Cora, Model: GraphSage, Attack: UGBA, Defense: Prune - ASR: 100.00%, Clean Accuracy: 74.86%\n",
            "Dataset: Cora, Model: GraphSage, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 40.30%\n",
            "Epoch 0, Loss: 0.0032\n",
            "Epoch 10, Loss: 0.0030\n",
            "Epoch 20, Loss: 0.0030\n",
            "Epoch 30, Loss: 0.0030\n",
            "Epoch 40, Loss: 0.0029\n",
            "Epoch 50, Loss: 0.0036\n",
            "Epoch 60, Loss: 0.0027\n",
            "Epoch 70, Loss: 0.0025\n",
            "Epoch 80, Loss: 0.0025\n",
            "Epoch 90, Loss: 0.0021\n",
            "Dataset: Cora, Model: GraphSage, Attack: DPGBA, Defense: None - ASR: 100.00%, Clean Accuracy: 88.54%\n",
            "Dataset: Cora, Model: GraphSage, Attack: DPGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.19%\n",
            "Dataset: Cora, Model: GraphSage, Attack: DPGBA, Defense: Prune - ASR: 100.00%, Clean Accuracy: 73.75%\n",
            "Dataset: Cora, Model: GraphSage, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 39.74%\n",
            "Epoch 0, Reconstruction Loss: 0.0220\n",
            "Epoch 10, Reconstruction Loss: 0.0159\n",
            "Epoch 20, Reconstruction Loss: 0.0135\n",
            "Epoch 30, Reconstruction Loss: 0.0125\n",
            "Epoch 40, Reconstruction Loss: 0.0121\n",
            "Epoch 0, Loss: 1.9654\n",
            "Epoch 10, Loss: 0.6828\n",
            "Epoch 20, Loss: 0.2882\n",
            "Epoch 30, Loss: 0.1913\n",
            "Epoch 40, Loss: 0.1376\n",
            "Epoch 50, Loss: 0.1021\n",
            "Epoch 60, Loss: 0.0786\n",
            "Epoch 70, Loss: 0.0604\n",
            "Epoch 80, Loss: 0.0490\n",
            "Epoch 90, Loss: 0.0393\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Samp, Defense: None - ASR: 100.00%, Clean Accuracy: 88.54%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 79.67%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Samp, Defense: Prune - ASR: 90.00%, Clean Accuracy: 83.18%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 44.92%\n",
            "Epoch 0, Loss: 0.0351\n",
            "Epoch 10, Loss: 0.0278\n",
            "Epoch 20, Loss: 0.0230\n",
            "Epoch 30, Loss: 0.0217\n",
            "Epoch 40, Loss: 0.0185\n",
            "Epoch 50, Loss: 0.0182\n",
            "Epoch 60, Loss: 0.0141\n",
            "Epoch 70, Loss: 0.0126\n",
            "Epoch 80, Loss: 0.0104\n",
            "Epoch 90, Loss: 0.0099\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Gen, Defense: None - ASR: 100.00%, Clean Accuracy: 87.43%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.37%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Gen, Defense: Prune - ASR: 90.00%, Clean Accuracy: 81.89%\n",
            "Dataset: Cora, Model: GAT, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.99%\n",
            "Epoch 0, Loss: 0.0150\n",
            "Epoch 10, Loss: 0.0095\n",
            "Epoch 20, Loss: 0.0095\n",
            "Epoch 30, Loss: 0.0076\n",
            "Epoch 40, Loss: 0.0082\n",
            "Epoch 50, Loss: 0.0071\n",
            "Epoch 60, Loss: 0.0072\n",
            "Epoch 70, Loss: 0.0063\n",
            "Epoch 80, Loss: 0.0065\n",
            "Epoch 90, Loss: 0.0060\n",
            "Dataset: Cora, Model: GAT, Attack: GTA, Defense: None - ASR: 100.00%, Clean Accuracy: 86.69%\n",
            "Dataset: Cora, Model: GAT, Attack: GTA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 78.00%\n",
            "Dataset: Cora, Model: GAT, Attack: GTA, Defense: Prune - ASR: 100.00%, Clean Accuracy: 79.67%\n",
            "Dataset: Cora, Model: GAT, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.62%\n",
            "Epoch 0, Loss: 0.0177\n",
            "Epoch 10, Loss: 0.0064\n",
            "Epoch 20, Loss: 0.0054\n",
            "Epoch 30, Loss: 0.0048\n",
            "Epoch 40, Loss: 0.0042\n",
            "Epoch 50, Loss: 0.0045\n",
            "Epoch 60, Loss: 0.0039\n",
            "Epoch 70, Loss: 0.0049\n",
            "Epoch 80, Loss: 0.0046\n",
            "Epoch 90, Loss: 0.0045\n",
            "Dataset: Cora, Model: GAT, Attack: UGBA, Defense: None - ASR: 90.00%, Clean Accuracy: 86.69%\n",
            "Dataset: Cora, Model: GAT, Attack: UGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 77.63%\n",
            "Dataset: Cora, Model: GAT, Attack: UGBA, Defense: Prune - ASR: 90.00%, Clean Accuracy: 79.67%\n",
            "Dataset: Cora, Model: GAT, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.62%\n",
            "Epoch 0, Loss: 0.0038\n",
            "Epoch 10, Loss: 0.0062\n",
            "Epoch 20, Loss: 0.0035\n",
            "Epoch 30, Loss: 0.0036\n",
            "Epoch 40, Loss: 0.0037\n",
            "Epoch 50, Loss: 0.0032\n",
            "Epoch 60, Loss: 0.0033\n",
            "Epoch 70, Loss: 0.0040\n",
            "Epoch 80, Loss: 0.0033\n",
            "Epoch 90, Loss: 0.0047\n",
            "Dataset: Cora, Model: GAT, Attack: DPGBA, Defense: None - ASR: 100.00%, Clean Accuracy: 86.88%\n",
            "Dataset: Cora, Model: GAT, Attack: DPGBA, Defense: Outlier Detection - ASR: 100.00%, Clean Accuracy: 77.82%\n",
            "Dataset: Cora, Model: GAT, Attack: DPGBA, Defense: Prune - ASR: 90.00%, Clean Accuracy: 79.67%\n",
            "Dataset: Cora, Model: GAT, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Reconstruction Loss: 0.0095\n",
            "Epoch 10, Reconstruction Loss: 0.0036\n",
            "Epoch 20, Reconstruction Loss: 0.0014\n",
            "Epoch 30, Reconstruction Loss: 0.0007\n",
            "Epoch 40, Reconstruction Loss: 0.0004\n",
            "Epoch 0, Loss: 1.1002\n",
            "Epoch 10, Loss: 1.0339\n",
            "Epoch 20, Loss: 0.9595\n",
            "Epoch 30, Loss: 0.8772\n",
            "Epoch 40, Loss: 0.7984\n",
            "Epoch 50, Loss: 0.7202\n",
            "Epoch 60, Loss: 0.6517\n",
            "Epoch 70, Loss: 0.5947\n",
            "Epoch 80, Loss: 0.5494\n",
            "Epoch 90, Loss: 0.5130\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Samp, Defense: None - ASR: 90.00%, Clean Accuracy: 84.30%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 82.50%, Clean Accuracy: 76.69%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Samp, Defense: Prune - ASR: 90.00%, Clean Accuracy: 82.17%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 40.65%\n",
            "Epoch 0, Loss: 0.4867\n",
            "Epoch 10, Loss: 0.4678\n",
            "Epoch 20, Loss: 0.4488\n",
            "Epoch 30, Loss: 0.4374\n",
            "Epoch 40, Loss: 0.4275\n",
            "Epoch 50, Loss: 0.4186\n",
            "Epoch 60, Loss: 0.4054\n",
            "Epoch 70, Loss: 0.4027\n",
            "Epoch 80, Loss: 0.3966\n",
            "Epoch 90, Loss: 0.3888\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Gen, Defense: None - ASR: 92.50%, Clean Accuracy: 86.58%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 72.50%, Clean Accuracy: 78.54%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Gen, Defense: Prune - ASR: 92.50%, Clean Accuracy: 83.90%\n",
            "Dataset: PubMed, Model: GCN, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.23%\n",
            "Epoch 0, Loss: 0.3814\n",
            "Epoch 10, Loss: 0.3791\n",
            "Epoch 20, Loss: 0.3751\n",
            "Epoch 30, Loss: 0.3705\n",
            "Epoch 40, Loss: 0.3671\n",
            "Epoch 50, Loss: 0.3632\n",
            "Epoch 60, Loss: 0.3595\n",
            "Epoch 70, Loss: 0.3564\n",
            "Epoch 80, Loss: 0.3569\n",
            "Epoch 90, Loss: 0.3519\n",
            "Dataset: PubMed, Model: GCN, Attack: GTA, Defense: None - ASR: 95.00%, Clean Accuracy: 87.29%\n",
            "Dataset: PubMed, Model: GCN, Attack: GTA, Defense: Outlier Detection - ASR: 0.00%, Clean Accuracy: 79.33%\n",
            "Dataset: PubMed, Model: GCN, Attack: GTA, Defense: Prune - ASR: 60.00%, Clean Accuracy: 84.07%\n",
            "Dataset: PubMed, Model: GCN, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.73%\n",
            "Epoch 0, Loss: 0.3484\n",
            "Epoch 10, Loss: 0.3475\n",
            "Epoch 20, Loss: 0.3446\n",
            "Epoch 30, Loss: 0.3437\n",
            "Epoch 40, Loss: 0.3426\n",
            "Epoch 50, Loss: 0.3391\n",
            "Epoch 60, Loss: 0.3374\n",
            "Epoch 70, Loss: 0.3336\n",
            "Epoch 80, Loss: 0.3331\n",
            "Epoch 90, Loss: 0.3303\n",
            "Dataset: PubMed, Model: GCN, Attack: UGBA, Defense: None - ASR: 95.00%, Clean Accuracy: 87.45%\n",
            "Dataset: PubMed, Model: GCN, Attack: UGBA, Defense: Outlier Detection - ASR: 85.00%, Clean Accuracy: 79.63%\n",
            "Dataset: PubMed, Model: GCN, Attack: UGBA, Defense: Prune - ASR: 92.50%, Clean Accuracy: 83.69%\n",
            "Dataset: PubMed, Model: GCN, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.53%\n",
            "Epoch 0, Loss: 0.3295\n",
            "Epoch 10, Loss: 0.3281\n",
            "Epoch 20, Loss: 0.3252\n",
            "Epoch 30, Loss: 0.3245\n",
            "Epoch 40, Loss: 0.3236\n",
            "Epoch 50, Loss: 0.3222\n",
            "Epoch 60, Loss: 0.3181\n",
            "Epoch 70, Loss: 0.3178\n",
            "Epoch 80, Loss: 0.3151\n",
            "Epoch 90, Loss: 0.3163\n",
            "Dataset: PubMed, Model: GCN, Attack: DPGBA, Defense: None - ASR: 95.00%, Clean Accuracy: 87.80%\n",
            "Dataset: PubMed, Model: GCN, Attack: DPGBA, Defense: Outlier Detection - ASR: 20.00%, Clean Accuracy: 79.91%\n",
            "Dataset: PubMed, Model: GCN, Attack: DPGBA, Defense: Prune - ASR: 92.50%, Clean Accuracy: 83.92%\n",
            "Dataset: PubMed, Model: GCN, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.73%\n",
            "Epoch 0, Reconstruction Loss: 0.0089\n",
            "Epoch 10, Reconstruction Loss: 0.0031\n",
            "Epoch 20, Reconstruction Loss: 0.0012\n",
            "Epoch 30, Reconstruction Loss: 0.0006\n",
            "Epoch 40, Reconstruction Loss: 0.0004\n",
            "Epoch 0, Loss: 1.0944\n",
            "Epoch 10, Loss: 1.0143\n",
            "Epoch 20, Loss: 0.8756\n",
            "Epoch 30, Loss: 0.7178\n",
            "Epoch 40, Loss: 0.5883\n",
            "Epoch 50, Loss: 0.5060\n",
            "Epoch 60, Loss: 0.4626\n",
            "Epoch 70, Loss: 0.4327\n",
            "Epoch 80, Loss: 0.4148\n",
            "Epoch 90, Loss: 0.3978\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Samp, Defense: None - ASR: 95.00%, Clean Accuracy: 86.84%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 87.50%, Clean Accuracy: 78.65%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Samp, Defense: Prune - ASR: 92.50%, Clean Accuracy: 82.50%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 41.47%\n",
            "Epoch 0, Loss: 0.3826\n",
            "Epoch 10, Loss: 0.3706\n",
            "Epoch 20, Loss: 0.3612\n",
            "Epoch 30, Loss: 0.3489\n",
            "Epoch 40, Loss: 0.3446\n",
            "Epoch 50, Loss: 0.3348\n",
            "Epoch 60, Loss: 0.3233\n",
            "Epoch 70, Loss: 0.3179\n",
            "Epoch 80, Loss: 0.3083\n",
            "Epoch 90, Loss: 0.3012\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Gen, Defense: None - ASR: 95.00%, Clean Accuracy: 88.66%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 75.00%, Clean Accuracy: 80.65%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Gen, Defense: Prune - ASR: 92.50%, Clean Accuracy: 83.64%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.56%\n",
            "Epoch 0, Loss: 0.3212\n",
            "Epoch 10, Loss: 0.2988\n",
            "Epoch 20, Loss: 0.2891\n",
            "Epoch 30, Loss: 0.2826\n",
            "Epoch 40, Loss: 0.2780\n",
            "Epoch 50, Loss: 0.2708\n",
            "Epoch 60, Loss: 0.2678\n",
            "Epoch 70, Loss: 0.2630\n",
            "Epoch 80, Loss: 0.2580\n",
            "Epoch 90, Loss: 0.2559\n",
            "Dataset: PubMed, Model: GraphSage, Attack: GTA, Defense: None - ASR: 95.00%, Clean Accuracy: 88.79%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: GTA, Defense: Outlier Detection - ASR: 0.00%, Clean Accuracy: 80.73%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: GTA, Defense: Prune - ASR: 67.50%, Clean Accuracy: 84.48%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.89%\n",
            "Epoch 0, Loss: 0.2535\n",
            "Epoch 10, Loss: 0.2483\n",
            "Epoch 20, Loss: 0.2432\n",
            "Epoch 30, Loss: 0.2380\n",
            "Epoch 40, Loss: 0.2363\n",
            "Epoch 50, Loss: 0.2317\n",
            "Epoch 60, Loss: 0.2290\n",
            "Epoch 70, Loss: 0.2253\n",
            "Epoch 80, Loss: 0.2244\n",
            "Epoch 90, Loss: 0.2189\n",
            "Dataset: PubMed, Model: GraphSage, Attack: UGBA, Defense: None - ASR: 92.50%, Clean Accuracy: 89.04%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: UGBA, Defense: Outlier Detection - ASR: 85.00%, Clean Accuracy: 80.95%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: UGBA, Defense: Prune - ASR: 90.00%, Clean Accuracy: 84.73%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.04%\n",
            "Epoch 0, Loss: 0.2202\n",
            "Epoch 10, Loss: 0.2149\n",
            "Epoch 20, Loss: 0.2128\n",
            "Epoch 30, Loss: 0.2084\n",
            "Epoch 40, Loss: 0.2057\n",
            "Epoch 50, Loss: 0.2026\n",
            "Epoch 60, Loss: 0.2015\n",
            "Epoch 70, Loss: 0.1970\n",
            "Epoch 80, Loss: 0.1933\n",
            "Epoch 90, Loss: 0.1901\n",
            "Dataset: PubMed, Model: GraphSage, Attack: DPGBA, Defense: None - ASR: 92.50%, Clean Accuracy: 89.22%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: DPGBA, Defense: Outlier Detection - ASR: 12.50%, Clean Accuracy: 81.23%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: DPGBA, Defense: Prune - ASR: 90.00%, Clean Accuracy: 84.91%\n",
            "Dataset: PubMed, Model: GraphSage, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 43.14%\n",
            "Epoch 0, Reconstruction Loss: 0.0092\n",
            "Epoch 10, Reconstruction Loss: 0.0036\n",
            "Epoch 20, Reconstruction Loss: 0.0014\n",
            "Epoch 30, Reconstruction Loss: 0.0006\n",
            "Epoch 40, Reconstruction Loss: 0.0004\n",
            "Epoch 0, Loss: 1.0985\n",
            "Epoch 10, Loss: 0.8943\n",
            "Epoch 20, Loss: 0.6741\n",
            "Epoch 30, Loss: 0.5198\n",
            "Epoch 40, Loss: 0.4457\n",
            "Epoch 50, Loss: 0.4118\n",
            "Epoch 60, Loss: 0.3906\n",
            "Epoch 70, Loss: 0.3748\n",
            "Epoch 80, Loss: 0.3637\n",
            "Epoch 90, Loss: 0.3543\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Samp, Defense: None - ASR: 95.00%, Clean Accuracy: 87.12%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 87.50%, Clean Accuracy: 78.87%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Samp, Defense: Prune - ASR: 90.00%, Clean Accuracy: 83.90%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.56%\n",
            "Epoch 0, Loss: 0.3461\n",
            "Epoch 10, Loss: 0.3393\n",
            "Epoch 20, Loss: 0.3314\n",
            "Epoch 30, Loss: 0.3232\n",
            "Epoch 40, Loss: 0.3168\n",
            "Epoch 50, Loss: 0.3082\n",
            "Epoch 60, Loss: 0.3031\n",
            "Epoch 70, Loss: 0.2950\n",
            "Epoch 80, Loss: 0.2895\n",
            "Epoch 90, Loss: 0.2822\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Gen, Defense: None - ASR: 92.50%, Clean Accuracy: 88.08%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Gen, Defense: Outlier Detection - ASR: 75.00%, Clean Accuracy: 79.46%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Gen, Defense: Prune - ASR: 87.50%, Clean Accuracy: 83.79%\n",
            "Dataset: PubMed, Model: GAT, Attack: SBA-Gen, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.58%\n",
            "Epoch 0, Loss: 0.2874\n",
            "Epoch 10, Loss: 0.2713\n",
            "Epoch 20, Loss: 0.2639\n",
            "Epoch 30, Loss: 0.2555\n",
            "Epoch 40, Loss: 0.2475\n",
            "Epoch 50, Loss: 0.2393\n",
            "Epoch 60, Loss: 0.2330\n",
            "Epoch 70, Loss: 0.2255\n",
            "Epoch 80, Loss: 0.2179\n",
            "Epoch 90, Loss: 0.2091\n",
            "Dataset: PubMed, Model: GAT, Attack: GTA, Defense: None - ASR: 97.50%, Clean Accuracy: 88.23%\n",
            "Dataset: PubMed, Model: GAT, Attack: GTA, Defense: Outlier Detection - ASR: 0.00%, Clean Accuracy: 79.74%\n",
            "Dataset: PubMed, Model: GAT, Attack: GTA, Defense: Prune - ASR: 62.50%, Clean Accuracy: 84.43%\n",
            "Dataset: PubMed, Model: GAT, Attack: GTA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.96%\n",
            "Epoch 0, Loss: 0.2113\n",
            "Epoch 10, Loss: 0.2024\n",
            "Epoch 20, Loss: 0.1933\n",
            "Epoch 30, Loss: 0.1852\n",
            "Epoch 40, Loss: 0.1781\n",
            "Epoch 50, Loss: 0.1715\n",
            "Epoch 60, Loss: 0.1615\n",
            "Epoch 70, Loss: 0.1553\n",
            "Epoch 80, Loss: 0.1484\n",
            "Epoch 90, Loss: 0.1429\n",
            "Dataset: PubMed, Model: GAT, Attack: UGBA, Defense: None - ASR: 97.50%, Clean Accuracy: 87.95%\n",
            "Dataset: PubMed, Model: GAT, Attack: UGBA, Defense: Outlier Detection - ASR: 85.00%, Clean Accuracy: 79.79%\n",
            "Dataset: PubMed, Model: GAT, Attack: UGBA, Defense: Prune - ASR: 85.00%, Clean Accuracy: 84.53%\n",
            "Dataset: PubMed, Model: GAT, Attack: UGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.81%\n",
            "Epoch 0, Loss: 0.1372\n",
            "Epoch 10, Loss: 0.1300\n",
            "Epoch 20, Loss: 0.1248\n",
            "Epoch 30, Loss: 0.1191\n",
            "Epoch 40, Loss: 0.1141\n",
            "Epoch 50, Loss: 0.1100\n",
            "Epoch 60, Loss: 0.1047\n",
            "Epoch 70, Loss: 0.0996\n",
            "Epoch 80, Loss: 0.0956\n",
            "Epoch 90, Loss: 0.0920\n",
            "Dataset: PubMed, Model: GAT, Attack: DPGBA, Defense: None - ASR: 97.50%, Clean Accuracy: 87.70%\n",
            "Dataset: PubMed, Model: GAT, Attack: DPGBA, Defense: Outlier Detection - ASR: 15.00%, Clean Accuracy: 79.79%\n",
            "Dataset: PubMed, Model: GAT, Attack: DPGBA, Defense: Prune - ASR: 80.00%, Clean Accuracy: 84.94%\n",
            "Dataset: PubMed, Model: GAT, Attack: DPGBA, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 42.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://drive.usercontent.google.com/download?id=1crmsTbd1-2sEXsGwa2IKnIB7Zd3TmUsy&confirm=t\n",
            "Downloading https://drive.usercontent.google.com/download?id=1join-XdvX3anJU_MLVtick7MgeAQiWIZ&confirm=t\n",
            "Downloading https://drive.usercontent.google.com/download?id=1uxIkbtg5drHTsKt-PAsZZ4_yJmgFmle9&confirm=t\n",
            "Downloading https://drive.usercontent.google.com/download?id=1htXCtuktuCW8TR8KiKfrFDAxUgekQoV7&confirm=t\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Reconstruction Loss: 3.6785\n",
            "Epoch 10, Reconstruction Loss: 3.3606\n",
            "Epoch 20, Reconstruction Loss: 2.9332\n",
            "Epoch 30, Reconstruction Loss: 2.7447\n",
            "Epoch 40, Reconstruction Loss: 2.6318\n",
            "Epoch 0, Loss: 2.0753\n",
            "Epoch 10, Loss: 1.6098\n",
            "Epoch 20, Loss: 1.5804\n",
            "Epoch 30, Loss: 1.5437\n",
            "Epoch 40, Loss: 1.5324\n",
            "Epoch 50, Loss: 1.5266\n",
            "Epoch 60, Loss: 1.5077\n",
            "Epoch 70, Loss: 1.4997\n",
            "Epoch 80, Loss: 1.4894\n",
            "Epoch 90, Loss: 1.4826\n",
            "Dataset: Flickr, Model: GCN, Attack: SBA-Samp, Defense: None - ASR: 41.88%, Clean Accuracy: 50.63%\n",
            "Dataset: Flickr, Model: GCN, Attack: SBA-Samp, Defense: Outlier Detection - ASR: 35.00%, Clean Accuracy: 44.87%\n",
            "Dataset: Flickr, Model: GCN, Attack: SBA-Samp, Defense: Prune - ASR: 41.88%, Clean Accuracy: 44.24%\n",
            "Dataset: Flickr, Model: GCN, Attack: SBA-Samp, Defense: Prune + LD - ASR: 0.00%, Clean Accuracy: 26.75%\n",
            "Epoch 0, Loss: 1.4751\n",
            "Epoch 10, Loss: 1.4660\n",
            "Epoch 20, Loss: 1.4602\n",
            "Epoch 30, Loss: 1.4527\n",
            "Epoch 40, Loss: 1.4487\n",
            "Epoch 50, Loss: 1.4472\n"
          ]
        }
      ]
    }
  ]
}