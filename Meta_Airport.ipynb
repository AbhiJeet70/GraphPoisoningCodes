{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiJeet70/GraphPoisoningCodes/blob/main/Meta_Airport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torch-geometric pandas matplotlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Airports\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.nn import GCNConv\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(20)\n",
        "\n",
        "# Define the GCN model\n",
        "class GCNNet(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNNet, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class MetaLearner(nn.Module):\n",
        "    def __init__(self, model, features, adj, labels, idx_train, lambda_=0.5):\n",
        "        super(MetaLearner, self).__init__()\n",
        "        self.model = model\n",
        "        self.features = features\n",
        "        self.adj = adj\n",
        "        self.labels = labels\n",
        "        self.idx_train = idx_train\n",
        "        self.lambda_ = lambda_\n",
        "        self.adj_changes = nn.Parameter(torch.zeros_like(adj.to_dense().float()))  # Convert to float\n",
        "\n",
        "    def forward(self, adj):\n",
        "        adj = adj + self.adj_changes\n",
        "        adj = torch.clamp(adj, 0, 1)\n",
        "        return adj\n",
        "\n",
        "    def loss(self, adj, output):\n",
        "        return F.cross_entropy(output[self.idx_train], self.labels[self.idx_train])\n",
        "\n",
        "def meta_attack(features, edge_index, labels, idx_train, idx_unlabeled, perturbations, lambda_=0.5, epochs=100):\n",
        "    num_nodes = features.size(0)\n",
        "\n",
        "    # Convert edge_index to dense adjacency matrix\n",
        "    adj = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.size(1)), (num_nodes, num_nodes)).to_dense()\n",
        "\n",
        "    # Initialize surrogate model\n",
        "    in_channels = features.size(1)\n",
        "    hidden_channels = 64\n",
        "    out_channels = labels.max().item() + 1\n",
        "    surrogate = GCNNet(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels)\n",
        "\n",
        "    # Initialize meta-learner\n",
        "    meta_learner = MetaLearner(model=surrogate, features=features, adj=adj, labels=labels, idx_train=idx_train, lambda_=lambda_)\n",
        "    optimizer = torch.optim.Adam(meta_learner.parameters(), lr=0.01)\n",
        "\n",
        "    # Perturb adjacency matrix\n",
        "    for _ in range(perturbations):\n",
        "        i = torch.randint(0, num_nodes, (1,))\n",
        "        j = torch.randint(0, num_nodes, (1,))\n",
        "        adj[i, j] = 1 - adj[i, j]\n",
        "        adj[j, i] = adj[i, j]  # Ensure symmetry\n",
        "\n",
        "    # Forward pass with surrogate model\n",
        "    surrogate.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        perturbed_adj = meta_learner(adj)  # Apply meta-learner to get perturbed adjacency\n",
        "        output = surrogate(features, edge_index)\n",
        "        loss = meta_learner.loss(perturbed_adj, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Return the perturbed adjacency matrix as edge_index\n",
        "    edge_index_perturbed = perturbed_adj.nonzero(as_tuple=False).t().contiguous()\n",
        "    return edge_index_perturbed\n",
        "\n",
        "# Define function to load Airports data for a given country\n",
        "def load_airports_data(country):\n",
        "    dataset = Airports(root='/tmp/Airports', name=country, transform=NormalizeFeatures())\n",
        "    data = dataset[0]\n",
        "    return data\n",
        "\n",
        "# Split data indices\n",
        "def split_indices(num_nodes, train_ratio=0.7, val_ratio=0.1):\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_end = int(train_ratio * num_nodes)\n",
        "    val_end = int((train_ratio + val_ratio) * num_nodes)\n",
        "    return torch.tensor(indices[:train_end]), torch.tensor(indices[train_end:val_end]), torch.tensor(indices[val_end:])\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, pyg_data, lr, weight_decay):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    pyg_data = pyg_data.to(device)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    best_val_acc = 0\n",
        "    patience = 100\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, 501):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(pyg_data.x, pyg_data.edge_index)\n",
        "        loss = F.cross_entropy(out[pyg_data.train_mask], pyg_data.y[pyg_data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        _, pred = model(pyg_data.x, pyg_data.edge_index).max(dim=1)\n",
        "        val_correct = float(pred[pyg_data.val_mask].eq(pyg_data.y[pyg_data.val_mask]).sum().item())\n",
        "        val_acc = val_correct / pyg_data.val_mask.sum().item()\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f'Early stopping at epoch {epoch}')\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.eval()\n",
        "    _, pred = model(pyg_data.x, pyg_data.edge_index).max(dim=1)\n",
        "    correct = float(pred[pyg_data.test_mask].eq(pyg_data.y[pyg_data.test_mask]).sum().item())\n",
        "    return correct / pyg_data.test_mask.sum().item()\n",
        "\n",
        "# Define dataset statistics\n",
        "def print_dataset_statistics(data, dataset_name):\n",
        "    num_nodes = data.num_nodes\n",
        "    num_edges = data.num_edges\n",
        "    num_features = data.num_node_features\n",
        "    num_classes = data.y.max().item() + 1\n",
        "    class_distribution = torch.bincount(data.y).cpu().numpy()\n",
        "    print(f\"Statistics for {dataset_name}:\")\n",
        "    print(f\"  Number of nodes: {num_nodes}\")\n",
        "    print(f\"  Number of edges: {num_edges}\")\n",
        "    print(f\"  Number of features: {num_features}\")\n",
        "    print(f\"  Number of classes: {num_classes}\")\n",
        "    print(f\"  Class distribution: {class_distribution}\")\n",
        "\n",
        "def run_meta_attack_experiments(data, perturbation_percentage, model, best_hyperparams):\n",
        "    train_idx = data.train_mask\n",
        "    val_idx = data.val_mask\n",
        "\n",
        "    perturbations = int(perturbation_percentage * data.edge_index.size(1))\n",
        "    perturbed_data = data.clone()\n",
        "    perturbed_edge_index = meta_attack(data.x, data.edge_index, data.y, train_idx, val_idx, perturbations)\n",
        "    perturbed_data.edge_index = perturbed_edge_index\n",
        "\n",
        "    # Ensure edge_index has valid indices\n",
        "    valid_indices = (perturbed_data.edge_index[0] < perturbed_data.num_nodes) & (perturbed_data.edge_index[1] < perturbed_data.num_nodes)\n",
        "    perturbed_data.edge_index = perturbed_data.edge_index[:, valid_indices]\n",
        "\n",
        "    # Evaluate model on perturbed data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(perturbed_data.x, perturbed_data.edge_index)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct = (pred[perturbed_data.test_mask] == perturbed_data.y[perturbed_data.test_mask]).sum().item()\n",
        "        acc = correct / perturbed_data.test_mask.sum().item()\n",
        "\n",
        "    return acc\n",
        "\n",
        "# Hyperparameter grid search\n",
        "hidden_channels_list = [16, 32, 64, 128, 256, 512]  # Reduced for quicker testing\n",
        "learning_rates = [0.1, 0.01, 0.001]  # Reduced for quicker testing\n",
        "weight_decays = [1e-4, 1e-5]\n",
        "\n",
        "# List of countries to process\n",
        "countries = ['USA', 'Brazil', 'Europe']\n",
        "\n",
        "# Initialize results DataFrame\n",
        "results_df = pd.DataFrame(columns=['Country', 'Hidden_Channels', 'Learning_Rate', 'Weight_Decay', 'Accuracy', 'Perturbation_Type', 'Perturbation_Percentage'])\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for country in countries:\n",
        "    print(f'Processing country: {country}')\n",
        "    data = load_airports_data(country)\n",
        "    print_dataset_statistics(data, country)\n",
        "\n",
        "    train_idx, val_idx, test_idx = split_indices(data.num_nodes)\n",
        "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool).to(device)\n",
        "    data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool).to(device)\n",
        "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool).to(device)\n",
        "    data.train_mask[train_idx] = True\n",
        "    data.val_mask[val_idx] = True\n",
        "    data.test_mask[test_idx] = True\n",
        "\n",
        "    num_classes = data.y.max().item() + 1  # Calculate the number of classes\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_hyperparams = {'Hidden_Channels': None, 'Learning_Rate': None, 'Weight_Decay': None}\n",
        "\n",
        "    for hidden_channels in hidden_channels_list:\n",
        "        for lr in learning_rates:\n",
        "            for wd in weight_decays:\n",
        "                model = GCNNet(data.num_node_features, hidden_channels, num_classes)\n",
        "                accuracy = train_model(model, data, lr, wd)\n",
        "                print(f'Hidden Channels: {hidden_channels}, Learning Rate: {lr}, Weight Decay: {wd}, Accuracy: {accuracy}')\n",
        "\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_hyperparams = {'Hidden_Channels': hidden_channels, 'Learning_Rate': lr, 'Weight_Decay': wd}\n",
        "\n",
        "    print(f'Best Hyperparameters for {country}: {best_hyperparams}, Accuracy: {best_accuracy}')\n",
        "\n",
        "    # Run meta-attack experiments for different perturbation percentages\n",
        "    perturbation_percentages = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
        "    perturbation_accuracies = []\n",
        "\n",
        "    for perturbation_percentage in perturbation_percentages:\n",
        "        acc = run_meta_attack_experiments(data, perturbation_percentage, model, best_hyperparams)\n",
        "        perturbation_accuracies.append(acc)\n",
        "        new_row = pd.DataFrame({\n",
        "            'Country': [country],\n",
        "            'Hidden_Channels': [best_hyperparams['Hidden_Channels']],\n",
        "            'Learning_Rate': [best_hyperparams['Learning_Rate']],\n",
        "            'Weight_Decay': [best_hyperparams['Weight_Decay']],\n",
        "            'Accuracy': [acc],\n",
        "            'Perturbation_Type': ['Meta'],\n",
        "            'Perturbation_Percentage': [perturbation_percentage]\n",
        "        })\n",
        "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "        print(f'Perturbation Percentage: {perturbation_percentage}, Accuracy: {acc}')\n",
        "\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('meta_attack_results.csv', index=False)\n",
        "\n",
        "print('Experiments completed and results saved to meta_attack_results.csv.')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-25T11:36:51.461374Z",
          "iopub.execute_input": "2024-07-25T11:36:51.462068Z",
          "iopub.status.idle": "2024-07-25T11:40:57.477999Z",
          "shell.execute_reply.started": "2024-07-25T11:36:51.462032Z",
          "shell.execute_reply": "2024-07-25T11:40:57.476956Z"
        },
        "trusted": true,
        "id": "bxYSyVb0sqxl",
        "outputId": "491c29c2-aa4f-44c2-f289-80d8bb5226c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: torch-geometric in /opt/conda/lib/python3.10/site-packages (2.5.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nProcessing country: USA\nStatistics for USA:\n  Number of nodes: 1190\n  Number of edges: 13599\n  Number of features: 1190\n  Number of classes: 4\n  Class distribution: [297 297 297 299]\nEarly stopping at epoch 106\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4435146443514644\nEarly stopping at epoch 105\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4560669456066946\nEarly stopping at epoch 126\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.42677824267782427\nEarly stopping at epoch 128\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.42677824267782427\nEarly stopping at epoch 408\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4435146443514644\nEarly stopping at epoch 337\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.4435146443514644\nEarly stopping at epoch 105\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4225941422594142\nEarly stopping at epoch 103\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4476987447698745\nEarly stopping at epoch 120\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.41841004184100417\nEarly stopping at epoch 126\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4309623430962343\nEarly stopping at epoch 228\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4393305439330544\nEarly stopping at epoch 233\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.4435146443514644\nEarly stopping at epoch 106\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4309623430962343\nEarly stopping at epoch 104\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4309623430962343\nEarly stopping at epoch 115\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.41422594142259417\nEarly stopping at epoch 119\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4309623430962343\nEarly stopping at epoch 252\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.42677824267782427\nEarly stopping at epoch 194\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.4393305439330544\nEarly stopping at epoch 109\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4393305439330544\nEarly stopping at epoch 104\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.42677824267782427\nEarly stopping at epoch 115\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4351464435146444\nEarly stopping at epoch 117\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.401673640167364\nEarly stopping at epoch 199\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4309623430962343\nEarly stopping at epoch 215\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.42677824267782427\nEarly stopping at epoch 105\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.42677824267782427\nEarly stopping at epoch 109\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4351464435146444\nEarly stopping at epoch 112\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.41422594142259417\nEarly stopping at epoch 112\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.41422594142259417\nEarly stopping at epoch 170\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4309623430962343\nEarly stopping at epoch 160\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.4393305439330544\nEarly stopping at epoch 119\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4225941422594142\nEarly stopping at epoch 105\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.41841004184100417\nEarly stopping at epoch 109\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.40585774058577406\nEarly stopping at epoch 110\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.40585774058577406\nEarly stopping at epoch 149\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4393305439330544\nEarly stopping at epoch 148\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.4351464435146444\nBest Hyperparameters for USA: {'Hidden_Channels': 16, 'Learning_Rate': 0.1, 'Weight_Decay': 1e-05}, Accuracy: 0.4560669456066946\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/3729115777.py:250: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Perturbation Percentage: 0.05, Accuracy: 0.4309623430962343\nPerturbation Percentage: 0.1, Accuracy: 0.4435146443514644\nPerturbation Percentage: 0.15, Accuracy: 0.4225941422594142\nPerturbation Percentage: 0.2, Accuracy: 0.38493723849372385\nPerturbation Percentage: 0.25, Accuracy: 0.41422594142259417\nProcessing country: Brazil\nStatistics for Brazil:\n  Number of nodes: 131\n  Number of edges: 1074\n  Number of features: 131\n  Number of classes: 4\n  Class distribution: [32 32 32 35]\nEarly stopping at epoch 106\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.48148148148148145\nEarly stopping at epoch 120\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 141\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4074074074074074\nEarly stopping at epoch 153\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4074074074074074\nEarly stopping at epoch 101\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2962962962962963\nEarly stopping at epoch 166\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.37037037037037035\nEarly stopping at epoch 114\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4074074074074074\nEarly stopping at epoch 200\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 154\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.3333333333333333\nEarly stopping at epoch 142\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4074074074074074\nEarly stopping at epoch 109\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2962962962962963\nEarly stopping at epoch 288\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.48148148148148145\nEarly stopping at epoch 104\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4074074074074074\nEarly stopping at epoch 104\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.37037037037037035\nEarly stopping at epoch 144\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.3333333333333333\nEarly stopping at epoch 120\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 258\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4444444444444444\nEarly stopping at epoch 104\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 108\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.37037037037037035\nEarly stopping at epoch 105\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.37037037037037035\nEarly stopping at epoch 136\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.3333333333333333\nEarly stopping at epoch 116\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 213\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2962962962962963\nEarly stopping at epoch 214\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 184\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4074074074074074\nEarly stopping at epoch 132\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4074074074074074\nEarly stopping at epoch 127\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.3333333333333333\nEarly stopping at epoch 112\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nEarly stopping at epoch 178\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.3333333333333333\nEarly stopping at epoch 180\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.37037037037037035\nEarly stopping at epoch 106\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4074074074074074\nEarly stopping at epoch 108\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.37037037037037035\nEarly stopping at epoch 123\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.2962962962962963\nEarly stopping at epoch 121\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.2962962962962963\nEarly stopping at epoch 170\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2962962962962963\nEarly stopping at epoch 167\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3333333333333333\nBest Hyperparameters for Brazil: {'Hidden_Channels': 16, 'Learning_Rate': 0.1, 'Weight_Decay': 0.0001}, Accuracy: 0.48148148148148145\nPerturbation Percentage: 0.05, Accuracy: 0.25925925925925924\nPerturbation Percentage: 0.1, Accuracy: 0.37037037037037035\nPerturbation Percentage: 0.15, Accuracy: 0.4074074074074074\nPerturbation Percentage: 0.2, Accuracy: 0.3333333333333333\nPerturbation Percentage: 0.25, Accuracy: 0.2962962962962963\nProcessing country: Europe\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Downloading https://github.com/leoribeiro/struc2vec/raw/master/graph/europe-airports.edgelist\nDownloading https://github.com/leoribeiro/struc2vec/raw/master/graph/labels-europe-airports.txt\nProcessing...\nDone!\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Statistics for Europe:\n  Number of nodes: 399\n  Number of edges: 5995\n  Number of features: 399\n  Number of classes: 4\n  Class distribution: [ 99  99  99 102]\nEarly stopping at epoch 103\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.4625\nEarly stopping at epoch 105\nHidden Channels: 16, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4625\nEarly stopping at epoch 102\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4375\nEarly stopping at epoch 285\nHidden Channels: 16, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4375\nEarly stopping at epoch 101\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2625\nEarly stopping at epoch 113\nHidden Channels: 16, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3\nEarly stopping at epoch 174\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.45\nEarly stopping at epoch 105\nHidden Channels: 32, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4625\nEarly stopping at epoch 101\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.425\nEarly stopping at epoch 101\nHidden Channels: 32, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.425\nEarly stopping at epoch 108\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.2875\nEarly stopping at epoch 106\nHidden Channels: 32, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.2875\nEarly stopping at epoch 106\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.475\nEarly stopping at epoch 105\nHidden Channels: 64, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.475\nEarly stopping at epoch 110\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.425\nEarly stopping at epoch 101\nHidden Channels: 64, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4625\nEarly stopping at epoch 108\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.3125\nEarly stopping at epoch 176\nHidden Channels: 64, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3875\nEarly stopping at epoch 108\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.425\nEarly stopping at epoch 108\nHidden Channels: 128, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.475\nEarly stopping at epoch 170\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4125\nEarly stopping at epoch 187\nHidden Channels: 128, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.425\nEarly stopping at epoch 105\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.3375\nEarly stopping at epoch 106\nHidden Channels: 128, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3625\nEarly stopping at epoch 109\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.475\nEarly stopping at epoch 109\nHidden Channels: 256, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.475\nEarly stopping at epoch 151\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4375\nEarly stopping at epoch 164\nHidden Channels: 256, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.4\nEarly stopping at epoch 104\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.35\nEarly stopping at epoch 101\nHidden Channels: 256, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.3625\nEarly stopping at epoch 109\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 0.0001, Accuracy: 0.425\nEarly stopping at epoch 146\nHidden Channels: 512, Learning Rate: 0.1, Weight Decay: 1e-05, Accuracy: 0.4375\nEarly stopping at epoch 140\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 0.0001, Accuracy: 0.4\nEarly stopping at epoch 128\nHidden Channels: 512, Learning Rate: 0.01, Weight Decay: 1e-05, Accuracy: 0.425\nEarly stopping at epoch 102\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 0.0001, Accuracy: 0.4\nEarly stopping at epoch 101\nHidden Channels: 512, Learning Rate: 0.001, Weight Decay: 1e-05, Accuracy: 0.375\nBest Hyperparameters for Europe: {'Hidden_Channels': 64, 'Learning_Rate': 0.1, 'Weight_Decay': 0.0001}, Accuracy: 0.475\nPerturbation Percentage: 0.05, Accuracy: 0.4\nPerturbation Percentage: 0.1, Accuracy: 0.3125\nPerturbation Percentage: 0.15, Accuracy: 0.2625\nPerturbation Percentage: 0.2, Accuracy: 0.25\nPerturbation Percentage: 0.25, Accuracy: 0.275\nExperiments completed and results saved to meta_attack_results.csv.\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}